# çº¿æ€§å›å½’

![image-20230912090316271](images/image-20230912090316271.png)

## çº¿æ€§å›å½’ä»‹ç»

**å­¦ä¹ ç›®æ ‡ï¼š**

1.ç†è§£çº¿æ€§å›å½’æ˜¯ä»€ä¹ˆï¼Ÿ

2.çŸ¥é“ä¸€å…ƒçº¿æ€§å›å½’å’Œå¤šå…ƒçº¿æ€§å›å½’çš„åŒºåˆ«

3.çŸ¥é“çº¿æ€§å›å½’çš„åº”ç”¨åœºæ™¯

### ã€ç†è§£ã€‘ä¸¾ä¸ªæ —å­

å‡è‹¥æœ‰äº†èº«é«˜å’Œä½“é‡æ•°æ®ï¼Œæ¥äº†æ’­ä»”çš„èº«é«˜ï¼Œä½ èƒ½é¢„æµ‹æ’­ä»”ä½“é‡å—?

![image-20230901101426794](images/image-20230901101426794.png)

 è¿™æ˜¯ä¸€ä¸ªå›å½’é—®é¢˜ï¼Œè¯¥å¦‚ä½•æ±‚è§£å‘¢?

**æ€è·¯**:å…ˆä»å·²çŸ¥èº«é«˜Xå’Œä½“é‡Yä¸­æ‰¾è§„å¾‹ï¼Œå†é¢„æµ‹

![image-20230901101621761](images/image-20230901101621761.png)

â€¢æ•°å­¦é—®é¢˜ï¼šç”¨ä¸€æ¡çº¿æ¥æ‹Ÿåˆèº«é«˜å’Œä½“é‡ä¹‹é—´çš„å…³ç³»ï¼Œå†å¯¹æ–°æ•°æ®è¿›è¡Œé¢„æµ‹

![image-20230901101918502](images/image-20230901101918502.png)

![image-20230901101931661](images/image-20230901101931661.png)

æ–¹ç¨‹ Y = kX + b

k160 + b = 56.3  -- (1)

k166 + b = 60.6  â€“- (2)

ã€‚ã€‚ã€‚ã€‚

k: æ–œç‡  b:æˆªè·

è‹¥ï¼šy = 0.9 x + (-93)

â€‹    0.9*176 +ï¼ˆ-93ï¼‰= ? 

### ã€ç†è§£ã€‘çº¿æ€§å›å½’

çº¿æ€§å›å½’(Linear regression)æ˜¯åˆ©ç”¨ **å›å½’æ–¹ç¨‹(å‡½æ•°)** å¯¹ **ä¸€ä¸ªæˆ–å¤šä¸ªè‡ªå˜é‡(ç‰¹å¾å€¼)å’Œå› å˜é‡(ç›®æ ‡å€¼)ä¹‹é—´** å…³ç³»è¿›è¡Œå»ºæ¨¡çš„ä¸€ç§åˆ†ææ–¹å¼ã€‚

![image-20230901102250602](images/image-20230901102250602.png)

![image-20230901102402944](images/image-20230901102402944.png)



æ³¨æ„äº‹é¡¹ï¼š

1 ä¸ºä»€ä¹ˆå«çº¿æ€§æ¨¡å‹ï¼Ÿå› ä¸ºæ±‚è§£çš„wï¼Œéƒ½æ˜¯wçš„é›¶æ¬¡å¹‚ï¼ˆå¸¸æ•°é¡¹ï¼‰æ‰€ä»¥å«æˆçº¿æ€§æ¨¡å‹

2 åœ¨çº¿æ€§å›å½’ä¸­ï¼Œä»æ•°æ®ä¸­è·å–çš„è§„å¾‹å…¶å®å°±æ˜¯å­¦ä¹ æƒé‡ç³»æ•°w

3 æŸä¸€ä¸ªæƒé‡å€¼wè¶Šå¤§ï¼Œè¯´æ˜è¿™ä¸ªæƒé‡çš„æ•°æ®å¯¹æˆ¿å­ä»·æ ¼å½±å“è¶Šå¤§ 



### ã€çŸ¥é“ã€‘çº¿æ€§å›å½’åˆ†ç±»

- ä¸€å…ƒçº¿æ€§å›å½’

y = kx +b 

ç›®æ ‡å€¼åªä¸ä¸€ä¸ªå› å˜é‡æœ‰å…³ç³»

![image-20230901102857178](images/image-20230901102857178.png)

- å¤šå…ƒçº¿æ€§å›å½’

![image-20230901102940614](images/image-20230901102940614.png)

ç›®æ ‡å€¼åªä¸å¤šä¸ªå› å˜é‡æœ‰å…³ç³»

![image-20230901103000204](images/image-20230901103000204.png)



### ã€çŸ¥é“ã€‘åº”ç”¨åœºæ™¯

![image-20230901103123601](images/image-20230901103123601.png)



## çº¿æ€§å›å½’é—®é¢˜çš„æ±‚è§£

**å­¦ä¹ ç›®æ ‡ï¼š**

1.çŸ¥é“çº¿æ€§å›å½’APIçš„ä½¿ç”¨

2.çŸ¥é“æŸå¤±å‡½æ•°æ˜¯ä»€ä¹ˆ

3.å¤ä¹ å¯¼æ•°å’ŒçŸ©é˜µçš„ç›¸å…³å†…å®¹

4.ç†è§£æ­£è§„æ–¹ç¨‹æ³•

5.æŒæ¡æ¢¯åº¦ä¸‹é™ç®—æ³•çš„å†…å®¹



### ã€å®æ“ã€‘çº¿æ€§å›å½’APIçš„åº”ç”¨

é¢„æµ‹æ’­ä»”èº«é«˜

å·²çŸ¥æ•°æ®:

![image-20230901104147248](images/image-20230901104147248.png)

 éœ€æ±‚:æ’­ä»”èº«é«˜æ˜¯176ï¼Œè¯·é¢„æµ‹ä½“é‡?



![image-20230901104237860](images/image-20230901104237860.png)



é€šè¿‡çº¿æ€§å›å½’APIå¯å¿«é€Ÿçš„æ‰¾åˆ°ä¸€æ¡çº¢è‰²ç›´çº¿ï¼Œæ˜¯æ€ä¹ˆæ±‚è§£çš„å‘¢ï¼Ÿ

![image-20230901104626001](images/image-20230901104626001.png)

### ã€æŒæ¡ã€‘æŸå¤±å‡½æ•°

éœ€è¦è®¾ç½®ä¸€ä¸ªè¯„åˆ¤æ ‡å‡†

![image-20230901110253313](images/image-20230901110253313.png)

 **è¯¯å·®æ¦‚å¿µ**ï¼šç”¨é¢„æµ‹å€¼y â€“ çœŸå®å€¼yå°±æ˜¯è¯¯å·®

**æŸå¤±å‡½æ•°**ï¼šè¡¡é‡æ¯ä¸ªæ ·æœ¬é¢„æµ‹å€¼ä¸çœŸå®å€¼æ•ˆæœçš„å‡½æ•°

â€œçº¢è‰²ç›´çº¿èƒ½æ›´å¥½çš„æ‹Ÿåˆæ‰€æœ‰ç‚¹â€ä¹Ÿå°±æ˜¯è¯¯å·®æœ€å°ï¼Œè¯¯å·®å’Œæœ€å°

æŸå¤±å‡½æ•°æ•°å­¦å¦‚ä½•è¡¨è¾¾å‘¢ï¼Ÿåˆå¦‚ä½•æ±‚æŸå¤±å‡½æ•°çš„æœ€å°å€¼å‘¢ï¼Ÿ

![image-20230901110606206](images/image-20230901110606206.png)

![image-20230901110842936](images/image-20230901110842936.png)

![image-20230901110853094](images/image-20230901110853094.png)

å½“æŸå¤±å‡½æ•°å–æœ€å°å€¼æ—¶ï¼Œå¾—åˆ°kå°±æ˜¯æœ€ä¼˜è§£

![image-20230901113810862](images/image-20230901113810862.png)

![image-20230901113822728](images/image-20230901113822728.png)

![image-20230901113834036](images/image-20230901113834036.png)

æƒ³æ±‚ä¸€æ¡ç›´çº¿æ›´å¥½çš„æ‹Ÿåˆæ‰€æœ‰ç‚¹ y = kx + b 

- â€‹     å¼•å…¥æŸå¤±å‡½æ•°(è¡¡é‡é¢„æµ‹å€¼å’ŒçœŸå®å€¼æ•ˆæœ) Loss(k, b) 

- â€‹     é€šè¿‡ä¸€ä¸ªä¼˜åŒ–æ–¹æ³•ï¼Œæ±‚æŸå¤±å‡½æ•°æœ€å°å€¼ï¼Œå¾—åˆ°Kæœ€ä¼˜è§£

![image-20230912103729099](images/image-20230912103729099.png)

å›å½’çš„æŸå¤±å‡½æ•°ï¼š

- *å‡æ–¹è¯¯å·®* *(*Mean-Square Error, MSE*)*

![image-20230901114527268](images/image-20230901114527268.png)

- *å¹³å‡ç»å¯¹è¯¯å·®* *(**Mean Absolute Error* *,* *MAE**)*

  ![image-20230901114539398](images/image-20230901114539398.png)



![image-20230901114816872](images/image-20230901114816872.png)





### ã€å¤ä¹ ã€‘å¯¼æ•°å’ŒçŸ©é˜µ

#### ã€çŸ¥é“ã€‘å¸¸è§çš„æ•°æ®è¡¨è¿°

- ä¸ºä»€ä¹ˆè¦å­¦ä¹ æ ‡é‡ã€å‘é‡ã€çŸ©é˜µã€å¼ é‡?
  - å› æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ä¸­ç»å¸¸ç”¨ï¼Œä¸è¦å› æ˜¯æ•°å­¦å°±å®³æ€•
  - å®—æ—¨:ç”¨åˆ°å°±å­¦ä»€ä¹ˆï¼Œä¸è¦ç›²ç›®çš„å±•å¼€ã€å¤§ç¯‡å¹…å­¦æ•°å­¦
- æ ‡é‡scalar :ä¸€ä¸ªç‹¬ç«‹å­˜åœ¨çš„æ•°ï¼Œåªæœ‰å¤§å°æ²¡æœ‰æ–¹å‘
- å‘é‡vector :å‘é‡æŒ‡ä¸€åˆ—é¡ºåºæ’åˆ—çš„å…ƒç´ ã€‚é»˜è®¤æ˜¯åˆ—å‘é‡

![image-20230901115201758](images/image-20230901115201758.png)

![image-20230901115210623](images/image-20230901115210623.png)

- çŸ©é˜µmatrix :äºŒç»´æ•°ç»„

  ![image-20230901115223778](images/image-20230901115223778.png)

  ![image-20230901115232323](images/image-20230901115232323.png)

- å¼ é‡Tensor :å¤šç»´æ•°ç»„ï¼Œå¼ é‡æ˜¯åŸºäºå‘é‡å’ŒçŸ©é˜µçš„æ¨å¹¿

  ![image-20230901115246275](images/image-20230901115246275.png)

#### ã€çŸ¥é“ã€‘å¯¼æ•°

å½“å‡½æ•°y=fï¼ˆxï¼‰çš„è‡ªå˜é‡xåœ¨ä¸€ç‚¹$x_0$ä¸Šäº§ç”Ÿä¸€ä¸ªå¢é‡Î”xæ—¶ï¼Œå‡½æ•°è¾“å‡ºå€¼çš„å¢é‡Î”yä¸è‡ªå˜é‡å¢é‡Î”xçš„æ¯”å€¼åœ¨Î”xè¶‹äº0æ—¶çš„æé™aå¦‚æœå­˜åœ¨ï¼Œaå³ä¸ºåœ¨$x_0$å¤„çš„å¯¼æ•°ï¼Œè®°ä½œ$f^\prime(x_0)$æˆ–df($x_0$)/dxã€‚

![](images/å¯¼æ•°.jpeg)



å¯¼æ•°æ˜¯å‡½æ•°çš„å±€éƒ¨æ€§è´¨ã€‚ä¸€ä¸ªå‡½æ•°åœ¨æŸä¸€ç‚¹çš„å¯¼æ•°æè¿°äº†è¿™ä¸ªå‡½æ•°åœ¨è¿™ä¸€ç‚¹é™„è¿‘çš„å˜åŒ–ç‡ã€‚

å‡½æ•°åœ¨æŸä¸€ç‚¹çš„å¯¼æ•°å°±æ˜¯è¯¥å‡½æ•°æ‰€ä»£è¡¨çš„æ›²çº¿åœ¨è¿™ä¸€ç‚¹ä¸Šçš„åˆ‡çº¿æ–œç‡

å¸¸è§å‡½æ•°çš„å¯¼æ•°ï¼š


|                        å…¬å¼                        |                             ä¾‹å­                             |
| :------------------------------------------------: | :----------------------------------------------------------: |
|                   $(C)^\prime=0$                   | $\left(5\right)^\prime=0$         $\left(10\right)^\prime=0$ |
| $\left(x^\alpha\right)^\prime=\alpha x^{\alpha-1}$ | $\left(x^3\right)^\prime=3 x^{2}$      $\left(x^5\right)^\prime=5 x^{4}$ |
|       $\left(a^x\right)^\prime=a^{x}\ln{a}$        | $\left(2^x\right)^\prime=2^x\ln{2}$      $\left(7^x\right)^\prime=7^x\ln{7}$ |
|          $\left(e^x\right)^\prime=e^{x}$           |               $\left(e^x\right)^\prime=e^{x}$                |
| $\left(\log{_a}x\right)^\prime=\frac{1}{x\ln{a}}$  | $\left(\log{_{10}}x\right)^\prime=\frac{1}{x\ln{10}}$      $\left(\log{_{6}}x\right)^\prime=\frac{1}{x\ln{6}}$ |
|      $\left(\ln{x}\right)^\prime=\frac{1}{x}$      |           $\left(\ln{x}\right)^\prime=\frac{1}{x}$           |
|       $\left(\sin{x}\right)^\prime=\cos{x}$        |            $\left(\sin{x}\right)^\prime=\cos{x}$             |
|       $\left(\cos{x}\right)^\prime=-\sin{x}$       |            $\left(\cos{x}\right)^\prime=-\sin{x}$            |

å¯¼æ•°çš„å››åˆ™è¿ç®—ï¼š

|                             å…¬å¼                             |                             ä¾‹å­                             |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| $\left[u(x)\pm v(x)\right]^\prime=u^\prime(x) \pm v^\prime(x)$ | $(e^x+4\ln{x})^\prime=(e^x)^\prime+(4\ln{x})^\prime=e^x+\frac{4}{x}$ |
| $\left[u(x)\cdot v(x)\right]^\prime=u^\prime(x) \cdot v(x) + u(x) \cdot v^\prime(x)$ | $(\sin{x}\cdot\ln{x})^\prime=\cos{x}\cdot\ln{x}+\sin{x}\cdot\frac{1}{x}$ |
| $\left[\frac{u(x)}{v(x)}\right]^\prime=\frac{u^\prime(x) \cdot v(x) - u(x) \cdot v^\prime(x)}{v^2(x)}$ | $\left(\frac{e^x}{\cos{x}}\right)^\prime=\frac{e^x\cdot\cos{x}-e^x\cdot(-\sin{x})}{cos^2(x)}$ |
|         $\{g[h(x)]\}^\prime=g^\prime(h)*h^\prime(x)$         |    $(\sin{2x})^\prime=\cos{2x}\cdot(2x)^\prime=2\cos(2x)$    |

å¤åˆå‡½æ•°æ±‚å¯¼ï¼šg(h)æ˜¯å¤–å‡½æ•° h(x)æ˜¯å†…å‡½æ•°ã€‚å…ˆå¯¹å¤–å‡½æ•°æ±‚å¯¼ï¼Œå†å¯¹å†…å‡½æ•°æ±‚å¯¼

![image-20230901143204713](images/image-20230901143204713.png)



å¯¼æ•°æ±‚æå€¼ï¼š

å¯¼æ•°ä¸º0çš„ä½ç½®æ˜¯å‡½æ•°çš„æå€¼ç‚¹ 

![image-20230901143529603](images/image-20230901143529603.png)

#### ã€çŸ¥é“ã€‘åå¯¼

![image-20230901144053678](images/image-20230901144053678.png)



![image-20230901144102962](images/image-20230901144102962.png)



#### ã€çŸ¥é“ã€‘å‘é‡

å‘é‡è¿ç®—ï¼š

![image-20230901144711751](images/image-20230901144711751.png)

![image-20230901145009232](images/image-20230901145009232.png)

#### ã€çŸ¥é“ã€‘çŸ©é˜µ

![image-20230901145231388](images/image-20230901145231388.png)

<img src="images/image-20230901145322438.png" alt="image-20230901145322438" />

![image-20230901145840373](images/image-20230901145840373.png)

![image-20230901150113602](images/image-20230901150113602.png)

### ã€äº†è§£ã€‘ä¸€å…ƒçº¿æ€§å›å½’çš„è§£æè§£

![image-20230901150406897](images/image-20230901150406897.png)



![image-20230901150708528](images/image-20230901150708528.png)

![image-20230912145402703](images/image-20230912145402703.png)

### ã€äº†è§£ã€‘å¤šå…ƒçº¿æ€§å›å½’çš„è§£æè§£-æ­£è§„æ–¹ç¨‹æ³•

![image-20230901152528805](images/image-20230901152528805.png)

![image-20230911234116911](images/image-20230911234116911.png)





![image-20230901152745308](images/image-20230901152745308.png)

![image-20230901152758396](images/image-20230901152758396.png)

### æ¢¯åº¦ä¸‹é™ç®—æ³•

#### ã€æŒæ¡ã€‘æ¢¯åº¦ä¸‹é™ç®—æ³•æ€æƒ³

ä»€ä¹ˆæ˜¯æ¢¯åº¦ä¸‹é™æ³•

â€¢ æ±‚è§£å‡½æ•°æå€¼è¿˜æœ‰æ›´é€šç”¨çš„æ–¹æ³•å°±æ˜¯æ¢¯åº¦ä¸‹é™æ³•ã€‚é¡¾åæ€ä¹‰:æ²¿ç€æ¢¯åº¦ä¸‹é™çš„æ–¹å‘æ±‚è§£æå°å€¼ â€¢ ä¸¾ä¸ªä¾‹å­:å¡åº¦æœ€é™¡ä¸‹å±±æ³•

![image-20230901183007785](images/image-20230901183007785.png)

- è¾“å…¥:åˆå§‹åŒ–ä½ç½®S;æ¯æ­¥è·ç¦»ä¸ºa ã€‚è¾“å‡º:ä»ä½ç½®Såˆ°è¾¾å±±åº•
- æ­¥éª¤1:ä»¤åˆå§‹åŒ–ä½ç½®ä¸ºå±±çš„ä»»æ„ä½ç½®S
- æ­¥éª¤2:åœ¨å½“å‰ä½ç½®ç¯é¡¾å››å‘¨ï¼Œå¦‚æœå››å‘¨éƒ½æ¯”Sé«˜è¿”å›S;å¦åˆ™æ‰§è¡Œæ­¥éª¤3
- æ­¥éª¤3: åœ¨å½“å‰ä½ç½®ç¯é¡¾å››å‘¨ï¼Œå¯»æ‰¾å¡åº¦æœ€é™¡çš„æ–¹å‘ï¼Œä»¤å…¶ä¸ºxæ–¹å‘
- æ­¥éª¤4:æ²¿ç€xæ–¹å‘å¾€ä¸‹èµ°ï¼Œé•¿åº¦ä¸ºaï¼Œåˆ°è¾¾æ–°çš„ä½ç½®Sâ€˜
- æ­¥éª¤5:åœ¨Sâ€˜ä½ç½®ç¯é¡¾å››å‘¨ï¼Œå¦‚æœå››å‘¨éƒ½æ¯”Sâ€˜é«˜ï¼Œåˆ™è¿”å›Sâ€˜ã€‚å¦åˆ™è½¬åˆ°æ­¥éª¤3

å°ç»“:é€šè¿‡å¾ªç¯è¿­ä»£çš„æ–¹æ³•ä¸æ–­æ›´æ–°ä½ç½®S (ç›¸å½“äºä¸æ–­æ›´æ–°æƒé‡å‚æ•°w)

![image-20230901183020726](images/image-20230901183020726.png)

 æœ€ç»ˆæ‰¾åˆ°æœ€ä¼˜è§£ è¿™ä¸ªæ–¹æ³•å¯ç”¨æ¥æ±‚æŸå¤±å‡½æ•°æœ€ä¼˜è§£ï¼Œ æ¯”æ­£è§„æ–¹ç¨‹æ›´é€šç”¨

```
æ¢¯åº¦ä¸‹é™è¿‡ç¨‹å°±å’Œä¸‹å±±åœºæ™¯ç±»ä¼¼
å¯å¾®åˆ†çš„æŸå¤±å‡½æ•°ï¼Œä»£è¡¨ç€ä¸€åº§å±±
å¯»æ‰¾çš„å‡½æ•°çš„æœ€å°å€¼ï¼Œä¹Ÿå°±æ˜¯å±±åº•
```

![image-20230901183113930](images/image-20230901183113930.png)



![image-20230901183125661](images/image-20230901183125661.png)

![image-20230912163031832](images/image-20230912163031832.png)

![image-20230901183139728](images/image-20230901183139728.png)



![image-20230901183152966](images/image-20230901183152966.png)







#### ã€ç†è§£ã€‘é“¶è¡Œä¿¡è´·æ¡ˆä¾‹

![image-20230901183222050](images/image-20230901183222050.png)

![image-20230901183240178](images/image-20230901183240178.png)



![image-20230901183301618](images/image-20230901183301618.png)



![image-20230901183315009](images/image-20230901183315009.png)





#### ã€äº†è§£ã€‘æ¢¯åº¦ä¸‹é™ç®—æ³•åˆ†ç±»

![image-20230901183333299](images/image-20230901183333299.png)

![image-20230901183346878](images/image-20230901183346878.png)





#### ã€ç†è§£ã€‘æ­£è§„æ–¹ç¨‹å’Œæ¢¯åº¦ä¸‹é™ç®—æ³•çš„å¯¹æ¯”

![image-20230901162716376](images/image-20230901162716376.png)

## å›å½’è¯„ä¼°æ–¹æ³•

**å­¦ä¹ ç›®æ ‡ï¼š**

1.æŒæ¡å¸¸ç”¨çš„å›å½’è¯„ä¼°æ–¹æ³•

2.äº†è§£ä¸åŒè¯„ä¼°æ–¹æ³•çš„ç‰¹ç‚¹



**ä¸ºä»€ä¹ˆè¦è¿›è¡Œçº¿æ€§å›å½’æ¨¡å‹çš„è¯„ä¼°**

æˆ‘ä»¬å¸Œæœ›è¡¡é‡é¢„æµ‹å€¼å’ŒçœŸå®å€¼ä¹‹é—´çš„å·®è·ï¼Œ

ä¼šç”¨åˆ°MAEã€MSEã€RMSEå¤šç§æµ‹è¯„å‡½æ•°è¿›è¡Œè¯„ä»·

### ã€çŸ¥é“ã€‘å¹³å‡ç»å¯¹è¯¯å·®

**Mean Absolute Error (MAE)**

![img](images/mae.png)

- ä¸Šé¢çš„å…¬å¼ä¸­ï¼šn ä¸ºæ ·æœ¬æ•°é‡, y ä¸ºå®é™…å€¼, $\hat{y}$ ä¸ºé¢„æµ‹å€¼

- MAE è¶Šå°æ¨¡å‹é¢„æµ‹çº¦å‡†ç¡®

Sklearn ä¸­MAEçš„API

```python
from sklearn.metrics import mean_absolute_error
mean_absolute_error(y_test,y_predict)
```

### ã€çŸ¥é“ã€‘å‡æ–¹è¯¯å·®

   **Mean Squared Error (MSE)**

![img](images/mse.png)

- ä¸Šé¢çš„å…¬å¼ä¸­ï¼šn ä¸ºæ ·æœ¬æ•°é‡, y ä¸ºå®é™…å€¼, $\hat{y}$ ä¸ºé¢„æµ‹å€¼
- MSE è¶Šå°æ¨¡å‹é¢„æµ‹çº¦å‡†ç¡®

Sklearn ä¸­MSEçš„API

```python
from sklearn.metrics import mean_squared_error
mean_squared_error(y_test,y_predict)
```

### ã€çŸ¥é“ã€‘ å‡æ–¹æ ¹è¯¯å·®

**Root Mean Squared Error (RMSE)**

![img](images/rmse.png)

- ä¸Šé¢çš„å…¬å¼ä¸­ï¼šn ä¸ºæ ·æœ¬æ•°é‡, y ä¸ºå®é™…å€¼, $\hat{y}$ ä¸ºé¢„æµ‹å€¼
- RMSE è¶Šå°æ¨¡å‹é¢„æµ‹çº¦å‡†ç¡®

### ã€äº†è§£ã€‘ ä¸‰ç§æŒ‡æ ‡çš„æ¯”è¾ƒ

æˆ‘ä»¬ç»˜åˆ¶äº†ä¸€æ¡ç›´çº¿ **y = 2x +5** ç”¨æ¥æ‹Ÿåˆ **y = 2x + 5 + e.** è¿™äº›æ•°æ®ç‚¹ï¼Œå…¶ä¸­eä¸ºå™ªå£°

![img](images/rmse2.png)

ä»ä¸Šå›¾ä¸­æˆ‘ä»¬å‘ç° MAE å’Œ RMSE éå¸¸æ¥è¿‘ï¼Œéƒ½è¡¨æ˜æ¨¡å‹çš„è¯¯å·®å¾ˆä½ï¼ˆMAE æˆ– RMSE è¶Šå°ï¼Œè¯¯å·®è¶Šå°ï¼ï¼‰ã€‚ ä½†æ˜¯MAE å’Œ RMSE æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿä¸ºä»€ä¹ˆMAEè¾ƒä½ï¼Ÿ

- å¯¹æ¯”MAE å’Œ RMSEçš„å…¬å¼ï¼ŒRMSEçš„è®¡ç®—å…¬å¼ä¸­æœ‰ä¸€ä¸ªå¹³æ–¹é¡¹ï¼Œå› æ­¤ï¼šå¤§çš„è¯¯å·®å°†è¢«å¹³æ–¹ï¼Œå› æ­¤ä¼šå¢åŠ  RMSE çš„å€¼

- å¯ä»¥å¾—å‡ºç»“è®ºï¼ŒRMSE ä¼šæ”¾å¤§é¢„æµ‹è¯¯å·®è¾ƒå¤§çš„æ ·æœ¬å¯¹ç»“æœçš„å½±å“ï¼Œè€Œ MAE åªæ˜¯ç»™å‡ºäº†å¹³å‡è¯¯å·®

- ç”±äº RMSE å¯¹è¯¯å·®çš„ **å¹³æ–¹å’Œæ±‚å¹³å‡** å†å¼€æ ¹å·ï¼Œå¤§å¤šæ•°æƒ…å†µä¸‹RMSE>MAE

  ä¸¾ä¾‹ (1+3)/2 = 2   $\sqrt{(1^2+3^2)/2 }= \sqrt{10/2} = \sqrt{5} = 2.236$

æˆ‘ä»¬å†çœ‹ä¸‹ä¸€ä¸ªä¾‹å­

![img](images/rmse3.png)

æ©™è‰²çº¿ä¸ç¬¬ä¸€å¼ å›¾ä¸­çš„ç›´çº¿ä¸€æ ·ï¼š**y = 2x +5** 

è“è‰²çš„ç‚¹ä¸ºï¼š **y = y + sin(x)\*exp(x/20) + e**  å…¶ä¸­ exp() è¡¨ç¤ºæŒ‡æ•°å‡½æ•°

æˆ‘ä»¬çœ‹åˆ°å¯¹æ¯”ç¬¬ä¸€å¼ å›¾ï¼Œæ‰€æœ‰çš„æŒ‡æ ‡éƒ½å˜å¤§äº†ï¼ŒRMSE å‡ ä¹æ˜¯ MAE å€¼çš„ä¸¤å€ï¼Œå› ä¸ºå®ƒå¯¹é¢„æµ‹è¯¯å·®è¾ƒå¤§çš„ç‚¹æ¯”è¾ƒæ•æ„Ÿ

æˆ‘ä»¬æ˜¯å¦å¯ä»¥å¾—å‡ºç»“è®ºï¼š RMSEæ˜¯æ›´å¥½çš„æŒ‡æ ‡ï¼Ÿ æŸäº›æƒ…å†µä¸‹MAEæ›´æœ‰ä¼˜åŠ¿ï¼Œä¾‹å¦‚ï¼š

- å‡è®¾æ•°æ®ä¸­æœ‰å°‘æ•°å¼‚å¸¸ç‚¹åå·®å¾ˆå¤§ï¼Œå¦‚æœæ­¤æ—¶æ ¹æ® RMSE é€‰æ‹©çº¿æ€§å›å½’æ¨¡å‹ï¼Œå¯èƒ½ä¼šé€‰å‡ºè¿‡æ‹Ÿåˆçš„æ¨¡å‹æ¥
- åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç”±äºæ•°æ®ä¸­çš„å¼‚å¸¸ç‚¹æå°‘ï¼Œé€‰æ‹©å…·æœ‰æœ€ä½ MAE çš„å›å½’æ¨¡å‹å¯èƒ½æ›´åˆé€‚
- é™¤æ­¤ä¹‹å¤–ï¼Œå½“ä¸¤ä¸ªæ¨¡å‹è®¡ç®—RMSEæ—¶æ•°æ®é‡ä¸ä¸€è‡´ï¼Œä¹Ÿä¸é€‚åˆåœ¨ä¸€èµ·æ¯”è¾ƒ 

## ã€å®æ“ã€‘æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹æ¡ˆä¾‹

### ã€çŸ¥é“ã€‘çº¿æ€§å›å½’API

sklearn.linear_model.LinearRegression(fit_intercept=True)

- é€šè¿‡æ­£è§„æ–¹ç¨‹ä¼˜åŒ–
- å‚æ•°ï¼šfit_interceptï¼Œæ˜¯å¦è®¡ç®—åç½®
- å±æ€§ï¼šLinearRegression.coef_ ï¼ˆå›å½’ç³»æ•°ï¼‰ LinearRegression.intercept_ï¼ˆåç½®ï¼‰

sklearn.linear_model.SGDRegressor(loss="squared_loss", fit_intercept=True, learning_rate ='constant', eta0=0.01)

- å‚æ•°ï¼šlossï¼ˆæŸå¤±å‡½æ•°ç±»å‹ï¼‰ï¼Œfit_interceptï¼ˆæ˜¯å¦è®¡ç®—åç½®ï¼‰learning_rate ï¼ˆå­¦ä¹ ç‡ï¼‰
- å±æ€§ï¼šSGDRegressor.coef_ ï¼ˆå›å½’ç³»æ•°ï¼‰SGDRegressor.intercept_ ï¼ˆåç½®ï¼‰

### ã€å®æ“ã€‘æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹

![image-20230913092037241](images/image-20230913092037241.png)

#### æ¡ˆä¾‹èƒŒæ™¯ä»‹ç»

æ•°æ®ä»‹ç»

![](images/006tNbRwly1ga8u37zooxj317g0tc7dk.jpg)

![Ã¥Â±ÂÃ¦Â€Â§](images/006tNbRwly1ga8u39xrmlj30xo0ryk16.jpg)

> ç»™å®šçš„è¿™äº›ç‰¹å¾ï¼Œæ˜¯ä¸“å®¶ä»¬å¾—å‡ºçš„å½±å“æˆ¿ä»·çš„ç»“æœå±æ€§ã€‚æˆ‘ä»¬æ­¤é˜¶æ®µä¸éœ€è¦è‡ªå·±å»æ¢ç©¶ç‰¹å¾æ˜¯å¦æœ‰ç”¨ï¼Œåªéœ€è¦ä½¿ç”¨è¿™äº›ç‰¹å¾ã€‚åˆ°åé¢é‡åŒ–å¾ˆå¤šç‰¹å¾éœ€è¦æˆ‘ä»¬è‡ªå·±å»å¯»æ‰¾



#### æ¡ˆä¾‹åˆ†æ

å›å½’å½“ä¸­çš„æ•°æ®å¤§å°ä¸ä¸€è‡´ï¼Œæ˜¯å¦ä¼šå¯¼è‡´ç»“æœå½±å“è¾ƒå¤§ã€‚æ‰€ä»¥éœ€è¦åšæ ‡å‡†åŒ–å¤„ç†ã€‚

- æ•°æ®åˆ†å‰²ä¸æ ‡å‡†åŒ–å¤„ç†
- å›å½’é¢„æµ‹
- çº¿æ€§å›å½’çš„ç®—æ³•æ•ˆæœè¯„ä¼°



####  å›å½’æ€§èƒ½è¯„ä¼°

å‡æ–¹è¯¯å·®(Mean Squared Error, MSE)è¯„ä»·æœºåˆ¶ï¼š

$\Large MSE = \frac{1}{m}\sum_{i=1}^{m}(y^i-\hat{y})^2$

sklearnä¸­çš„APIï¼šsklearn.metrics.mean_squared_error(y_true, y_pred)

- å‡æ–¹è¯¯å·®å›å½’æŸå¤±
- y_true:çœŸå®å€¼
- y_pred:é¢„æµ‹å€¼
- return:æµ®ç‚¹æ•°ç»“æœ



#### ä»£ç å®ç°

```python
# 0.å¯¼åŒ…
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression,SGDRegressor
from sklearn.metrics import mean_squared_error

# 1.åŠ è½½æ•°æ®
boston = load_boston()
# print(boston)

# 2.æ•°æ®é›†åˆ’åˆ†
x_train,x_test,y_train,y_test =train_test_split(boston.data,boston.target,test_size=0.2,random_state=22)

# 3.æ ‡å‡†åŒ–
process=StandardScaler()
x_train=process.fit_transform(x_train)
x_test=process.transform(x_test)

# 4.æ¨¡å‹è®­ç»ƒ
# 4.1 å®ä¾‹åŒ–(æ­£è§„æ–¹ç¨‹)
# model =LinearRegression(fit_intercept=True)
model = SGDRegressor(learning_rate='constant',eta0=0.01)
# 4.2 fit
model.fit(x_train,y_train)

# print(model.coef_)
# print(model.intercept_)
# 5.é¢„æµ‹
y_predict=model.predict(x_test)

print(y_predict)

# 6.æ¨¡å‹è¯„ä¼°

print(mean_squared_error(y_test,y_predict))


```



1.2.0 ä»¥ä¸Šç‰ˆæœ¬å®ç°

```python
# 0.å¯¼åŒ…
# from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression,SGDRegressor
from sklearn.metrics import mean_squared_error

# 1.åŠ è½½æ•°æ®
# boston = load_boston()
# print(boston)
import pandas as pd
import numpy as np


data_url = "http://lib.stat.cmu.edu/datasets/boston"
raw_df = pd.read_csv(data_url, sep="\s+", skiprows=22, header=None)
data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])
target = raw_df.values[1::2, 2]

# 2.æ•°æ®é›†åˆ’åˆ†
# x_train,x_test,y_train,y_test =train_test_split(boston.data,boston.target,test_size=0.2,random_state=22)
x_train,x_test,y_train,y_test =train_test_split(data,target,test_size=0.2,random_state=22)

# 3.æ ‡å‡†åŒ–
process=StandardScaler()
x_train=process.fit_transform(x_train)
x_test=process.transform(x_test)

# 4.æ¨¡å‹è®­ç»ƒ
# 4.1 å®ä¾‹åŒ–(æ­£è§„æ–¹ç¨‹)
# model =LinearRegression(fit_intercept=True)
model = SGDRegressor(learning_rate='constant',eta0=0.01)
# 4.2 fit
model.fit(x_train,y_train)

# print(model.coef_)
# print(model.intercept_)
# 5.é¢„æµ‹
y_predict=model.predict(x_test)

print(y_predict)

# 6.æ¨¡å‹è¯„ä¼°

print(mean_squared_error(y_test,y_predict))


```



## æ­£åˆ™åŒ–

**å­¦ä¹ ç›®æ ‡ï¼š**

1.æŒæ¡è¿‡æ‹Ÿåˆã€æ¬ æ‹Ÿåˆçš„æ¦‚å¿µ

2.æŒæ¡è¿‡æ‹Ÿåˆã€æ¬ æ‹Ÿåˆäº§ç”Ÿçš„åŸå› 

3.çŸ¥é“ä»€ä¹ˆæ˜¯æ­£åˆ™åŒ–ï¼Œä»¥åŠæ­£åˆ™åŒ–çš„æ–¹æ³•

### ã€ç†è§£ã€‘ æ¬ æ‹Ÿåˆä¸è¿‡æ‹Ÿåˆ

è¿‡æ‹Ÿåˆï¼šä¸€ä¸ªå‡è®¾ **åœ¨è®­ç»ƒæ•°æ®ä¸Šèƒ½å¤Ÿè·å¾—æ¯”å…¶ä»–å‡è®¾æ›´å¥½çš„æ‹Ÿåˆï¼Œ ä½†æ˜¯åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šå´ä¸èƒ½å¾ˆå¥½åœ°æ‹Ÿåˆæ•°æ®** (ä½“ç°åœ¨å‡†ç¡®ç‡ä¸‹é™)ï¼Œæ­¤æ—¶è®¤ä¸ºè¿™ä¸ªå‡è®¾å‡ºç°äº†è¿‡æ‹Ÿåˆçš„ç°è±¡ã€‚(æ¨¡å‹è¿‡äºå¤æ‚)

æ¬ æ‹Ÿåˆï¼šä¸€ä¸ªå‡è®¾ **åœ¨è®­ç»ƒæ•°æ®ä¸Šä¸èƒ½è·å¾—æ›´å¥½çš„æ‹Ÿåˆï¼Œå¹¶ä¸”åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šä¹Ÿä¸èƒ½å¾ˆå¥½åœ°æ‹Ÿåˆæ•°æ®** ï¼Œæ­¤æ—¶è®¤ä¸ºè¿™ä¸ªå‡è®¾å‡ºç°äº†æ¬ æ‹Ÿåˆçš„ç°è±¡ã€‚(æ¨¡å‹è¿‡äºç®€å•)

è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆçš„åŒºåˆ«ï¼š

<img src="images/006tNbRwly1ga8u2rlw69j315m0oc40y.jpg" alt="Ã¦Â¬ Ã¦Â‹ÂŸÃ¥ÂÂˆÃ¨Â¿Â‡Ã¦Â‹ÂŸÃ¥ÂÂˆÃ¥Â›Â¾Ã§Â¤Âº" style="zoom: 33%;" />

æ¬ æ‹Ÿåˆåœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸Šçš„è¯¯å·®éƒ½è¾ƒå¤§

è¿‡æ‹Ÿåˆåœ¨è®­ç»ƒé›†ä¸Šè¯¯å·®è¾ƒå°ï¼Œè€Œæµ‹è¯•é›†ä¸Šè¯¯å·®è¾ƒå¤§

![image-20230913101352444](images/image-20230913101352444.png)

### ã€å®è·µã€‘é€šè¿‡ä»£ç è®¤è¯†è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆ

ç»˜åˆ¶æ•°æ®

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error  # è®¡ç®—å‡æ–¹è¯¯å·®
from sklearn.model_selection import train_test_split


def dm01_æ¬ æ‹Ÿåˆ():
    # 1. å‡†å¤‡x, yæ•°æ®, å¢åŠ ä¸Šå™ªå£°.
    # ç”¨äºè®¾ç½®éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­ï¼ˆseedï¼‰, ç§å­ä¸€æ ·, æ¯æ¬¡ç”Ÿæˆç›¸åŒåºåˆ—.
    np.random.seed(666)
    # x: éšæœºæ•°, èŒƒå›´ä¸º (-3, 3), 100ä¸ª.
    x = np.random.uniform(-3, 3, size=100)
    # loc: å‡å€¼, scale: æ ‡å‡†å·®, normal: æ­£æ€åˆ†å¸ƒ.
    y = 0.5 * x ** 2 + x + 2 + np.random.normal(0, 1, size=100)
    # 2. å®ä¾‹åŒ– çº¿æ€§å›å½’æ¨¡å‹.
    estimator = LinearRegression()
    # 3. è®­ç»ƒæ¨¡å‹
    X = x.reshape(-1, 1)
    estimator.fit(X, y)

    # 4. æ¨¡å‹é¢„æµ‹.
    y_predict = estimator.predict(X)
    print("é¢„æµ‹å€¼:", y_predict)

    # 5. è®¡ç®—å‡æ–¹è¯¯å·® => æ¨¡å‹è¯„ä¼°
    print(f'å‡æ–¹è¯¯å·®: {mean_squared_error(y, y_predict)}')
    # 6. ç”»å›¾
    plt.scatter(x, y)           # æ•£ç‚¹å›¾
    plt.plot(x, y_predict, color='r')   # æŠ˜çº¿å›¾(é¢„æµ‹å€¼, æ‹Ÿåˆå›å½’çº¿)
    plt.show()                  # å…·ä½“çš„ç»˜å›¾



if __name__ == '__main__':
    dm01_æ¬ æ‹Ÿåˆ()

```

![1](images/1.png)

```python
#è®¡ç®—å‡æ–¹è¯¯å·®
from sklearn.metrics import mean_squared_error
mean_squared_error(y,y_predict)

#3.0750025765636577
```

æ·»åŠ äºŒæ¬¡é¡¹ï¼Œç»˜åˆ¶å›¾åƒ

```python
def dm02_æ¨¡å‹ok():
    # 1. å‡†å¤‡x, yæ•°æ®, å¢åŠ ä¸Šå™ªå£°.
    # ç”¨äºè®¾ç½®éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­ï¼ˆseedï¼‰, ç§å­ä¸€æ ·, æ¯æ¬¡ç”Ÿæˆç›¸åŒåºåˆ—.
    np.random.seed(666)
    # x: éšæœºæ•°, èŒƒå›´ä¸º (-3, 3), 100ä¸ª.
    x = np.random.uniform(-3, 3, size=100)
    # loc: å‡å€¼, scale: æ ‡å‡†å·®, normal: æ­£æ€åˆ†å¸ƒ.
    y = 0.5 * x ** 2 + x + 2 + np.random.normal(0, 1, size=100)
    # 2. å®ä¾‹åŒ– çº¿æ€§å›å½’æ¨¡å‹.
    estimator = LinearRegression()
    # 3. è®­ç»ƒæ¨¡å‹
    X = x.reshape(-1, 1)
    X2 = np.hstack([X, X ** 2])
    estimator.fit(X2, y)

    # 4. æ¨¡å‹é¢„æµ‹.
    y_predict = estimator.predict(X2)
    print("é¢„æµ‹å€¼:", y_predict)

    # 5. è®¡ç®—å‡æ–¹è¯¯å·® => æ¨¡å‹è¯„ä¼°
    print(f'å‡æ–¹è¯¯å·®: {mean_squared_error(y, y_predict)}')
    # 6. ç”»å›¾
    plt.scatter(x, y)  # æ•£ç‚¹å›¾
    # sort()  è¯¥å‡½æ•°ç›´æ¥è¿”å›ä¸€ä¸ªæ’åºåçš„æ–°æ•°ç»„ã€‚
    # numpy.argsort()   è¯¥å‡½æ•°è¿”å›çš„æ˜¯æ•°ç»„å€¼ä»å°åˆ°å¤§æ’åºæ—¶å¯¹åº”çš„ç´¢å¼•å€¼
    plt.plot(np.sort(x), y_predict[np.argsort(x)], color='r')  # æŠ˜çº¿å›¾(é¢„æµ‹å€¼, æ‹Ÿåˆå›å½’çº¿)
    # plt.plot(x, y_predict)
    plt.show()  # å…·ä½“çš„ç»˜å›¾
```

![2](images/2.png)

```python
#è®¡ç®—å‡æ–¹è¯¯å·®å’Œå‡†ç¡®ç‡

from sklearn.metrics import mean_squared_error
mean_squared_error(y,y_predict2)

#1.0987392142417858
```

å†æ¬¡åŠ å…¥é«˜æ¬¡é¡¹ï¼Œç»˜åˆ¶å›¾åƒï¼Œè§‚å¯Ÿå‡æ–¹è¯¯å·®ç»“æœ

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error  # è®¡ç®—å‡æ–¹è¯¯å·®
from sklearn.model_selection import train_test_split


def dm01_æ¬ æ‹Ÿåˆ():
    # 1. å‡†å¤‡x, yæ•°æ®, å¢åŠ ä¸Šå™ªå£°.
    # ç”¨äºè®¾ç½®éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­ï¼ˆseedï¼‰, ç§å­ä¸€æ ·, æ¯æ¬¡ç”Ÿæˆç›¸åŒåºåˆ—.
    np.random.seed(666)
    # x: éšæœºæ•°, èŒƒå›´ä¸º (-3, 3), 100ä¸ª.
    x = np.random.uniform(-3, 3, size=100)
    # loc: å‡å€¼, scale: æ ‡å‡†å·®, normal: æ­£æ€åˆ†å¸ƒ.
    y = 0.5 * x ** 2 + x + 2 + np.random.normal(0, 1, size=100)
    # 2. å®ä¾‹åŒ– çº¿æ€§å›å½’æ¨¡å‹.
    estimator = LinearRegression()
    # 3. è®­ç»ƒæ¨¡å‹
    X = x.reshape(-1, 1)
    estimator.fit(X, y)

    # 4. æ¨¡å‹é¢„æµ‹.
    y_predict = estimator.predict(X)
    print("é¢„æµ‹å€¼:", y_predict)

    # 5. è®¡ç®—å‡æ–¹è¯¯å·® => æ¨¡å‹è¯„ä¼°
    print(f'å‡æ–¹è¯¯å·®: {mean_squared_error(y, y_predict)}')
    # 6. ç”»å›¾
    plt.scatter(x, y)           # æ•£ç‚¹å›¾
    plt.plot(x, y_predict, color='r')   # æŠ˜çº¿å›¾(é¢„æµ‹å€¼, æ‹Ÿåˆå›å½’çº¿)
    plt.show()                  # å…·ä½“çš„ç»˜å›¾

def dm02_æ¨¡å‹ok():
    # 1. å‡†å¤‡x, yæ•°æ®, å¢åŠ ä¸Šå™ªå£°.
    # ç”¨äºè®¾ç½®éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­ï¼ˆseedï¼‰, ç§å­ä¸€æ ·, æ¯æ¬¡ç”Ÿæˆç›¸åŒåºåˆ—.
    np.random.seed(666)
    # x: éšæœºæ•°, èŒƒå›´ä¸º (-3, 3), 100ä¸ª.
    x = np.random.uniform(-3, 3, size=100)
    # loc: å‡å€¼, scale: æ ‡å‡†å·®, normal: æ­£æ€åˆ†å¸ƒ.
    y = 0.5 * x ** 2 + x + 2 + np.random.normal(0, 1, size=100)
    # 2. å®ä¾‹åŒ– çº¿æ€§å›å½’æ¨¡å‹.
    estimator = LinearRegression()
    # 3. è®­ç»ƒæ¨¡å‹
    X = x.reshape(-1, 1)
    X2 = np.hstack([X, X ** 2])
    estimator.fit(X2, y)

    # 4. æ¨¡å‹é¢„æµ‹.
    y_predict = estimator.predict(X2)
    print("é¢„æµ‹å€¼:", y_predict)

    # 5. è®¡ç®—å‡æ–¹è¯¯å·® => æ¨¡å‹è¯„ä¼°
    print(f'å‡æ–¹è¯¯å·®: {mean_squared_error(y, y_predict)}')
    # 6. ç”»å›¾
    plt.scatter(x, y)  # æ•£ç‚¹å›¾
    # sort()  è¯¥å‡½æ•°ç›´æ¥è¿”å›ä¸€ä¸ªæ’åºåçš„æ–°æ•°ç»„ã€‚
    # numpy.argsort()   è¯¥å‡½æ•°è¿”å›çš„æ˜¯æ•°ç»„å€¼ä»å°åˆ°å¤§æ’åºæ—¶å¯¹åº”çš„ç´¢å¼•å€¼
    plt.plot(np.sort(x), y_predict[np.argsort(x)], color='r')  # æŠ˜çº¿å›¾(é¢„æµ‹å€¼, æ‹Ÿåˆå›å½’çº¿)
    # plt.plot(x, y_predict)
    plt.show()  # å…·ä½“çš„ç»˜å›¾


def dm03_è¿‡æ‹Ÿåˆ():
    # 1. å‡†å¤‡x, yæ•°æ®, å¢åŠ ä¸Šå™ªå£°.
    # ç”¨äºè®¾ç½®éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­ï¼ˆseedï¼‰, ç§å­ä¸€æ ·, æ¯æ¬¡ç”Ÿæˆç›¸åŒåºåˆ—.
    np.random.seed(666)
    # x: éšæœºæ•°, èŒƒå›´ä¸º (-3, 3), 100ä¸ª.
    x = np.random.uniform(-3, 3, size=100)
    # loc: å‡å€¼, scale: æ ‡å‡†å·®, normal: æ­£æ€åˆ†å¸ƒ.
    y = 0.5 * x ** 2 + x + 2 + np.random.normal(0, 1, size=100)
    # 2. å®ä¾‹åŒ– çº¿æ€§å›å½’æ¨¡å‹.
    estimator = LinearRegression()
    # 3. è®­ç»ƒæ¨¡å‹
    X = x.reshape(-1, 1)
    # hstack() å‡½æ•°ç”¨äºå°†å¤šä¸ªæ•°ç»„åœ¨è¡Œä¸Šå †å èµ·æ¥, å³: æ•°æ®å¢åŠ é«˜æ¬¡é¡¹.
    X3 = np.hstack([X, X**2, X**3, X**4, X**5, X**6, X**7, X**8, X**9, X**10])
    estimator.fit(X3, y)

    # 4. æ¨¡å‹é¢„æµ‹.
    y_predict = estimator.predict(X3)
    print("é¢„æµ‹å€¼:", y_predict)

    # 5. è®¡ç®—å‡æ–¹è¯¯å·® => æ¨¡å‹è¯„ä¼°
    print(f'å‡æ–¹è¯¯å·®: {mean_squared_error(y, y_predict)}')
    # 6. ç”»å›¾
    plt.scatter(x, y)  # æ•£ç‚¹å›¾
    # sort()  è¯¥å‡½æ•°ç›´æ¥è¿”å›ä¸€ä¸ªæ’åºåçš„æ–°æ•°ç»„ã€‚
    # numpy.argsort()   è¯¥å‡½æ•°è¿”å›çš„æ˜¯æ•°ç»„å€¼ä»å°åˆ°å¤§æ’åºæ—¶å¯¹åº”çš„ç´¢å¼•å€¼
    plt.plot(np.sort(x), y_predict[np.argsort(x)], color='r')  # æŠ˜çº¿å›¾(é¢„æµ‹å€¼, æ‹Ÿåˆå›å½’çº¿)
    plt.show()  # å…·ä½“çš„ç»˜å›¾

if __name__ == '__main__':
    # dm01_æ¬ æ‹Ÿåˆ()
    # dm02_æ¨¡å‹ok()
    dm03_è¿‡æ‹Ÿåˆ()

```

![](images/3.png)

é€šè¿‡ä¸Šè¿°è§‚å¯Ÿå‘ç°ï¼Œéšç€åŠ å…¥çš„é«˜æ¬¡é¡¹è¶Šæ¥è¶Šå¤šï¼Œæ‹Ÿåˆç¨‹åº¦è¶Šæ¥è¶Šé«˜ï¼Œå‡æ–¹è¯¯å·®ä¹Ÿéšç€åŠ å…¥è¶Šæ¥è¶Šå°ã€‚è¯´æ˜å·²ç»ä¸å†æ¬ æ‹Ÿåˆäº†ã€‚

é—®é¢˜ï¼šå¦‚ä½•åˆ¤æ–­å‡ºç°è¿‡æ‹Ÿåˆå‘¢ï¼Ÿ

å°†æ•°æ®é›†è¿›è¡Œåˆ’åˆ†ï¼šå¯¹æ¯”Xã€X2ã€X5çš„æµ‹è¯•é›†çš„å‡æ–¹è¯¯å·®

Xçš„æµ‹è¯•é›†å‡æ–¹è¯¯å·®

```python
X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 5)
estimator = LinearRegression()
estimator.fit(X_train,y_train)
y_predict = estimator.predict(X_test)

mean_squared_error(y_test,y_predict)
#3.153139806483088
```

X2çš„æµ‹è¯•é›†å‡æ–¹è¯¯å·®

```python
X_train,X_test,y_train,y_test = train_test_split(X2,y,random_state = 5)
estimator = LinearRegression()
estimator.fit(X_train,y_train)
y_predict = estimator.predict(X_test)
mean_squared_error(y_test,y_predict)
#1.111873885731967
```

X5çš„æµ‹è¯•é›†çš„å‡æ–¹è¯¯å·®

```python
X_train,X_test,y_train,y_test = train_test_split(X5,y,random_state = 5)
estimator = LinearRegression()
estimator.fit(X_train,y_train)
y_predict = estimator.predict(X_test)
mean_squared_error(y_test,y_predict)
#1.4145580542309835
```

### ã€ç†è§£ã€‘ åŸå› ä»¥åŠè§£å†³åŠæ³•

**æ¬ æ‹Ÿåˆäº§ç”ŸåŸå› ï¼š** å­¦ä¹ åˆ°æ•°æ®çš„ç‰¹å¾è¿‡å°‘

è§£å†³åŠæ³•ï¼š

**1ï¼‰æ·»åŠ å…¶ä»–ç‰¹å¾é¡¹**ï¼Œæœ‰æ—¶å‡ºç°æ¬ æ‹Ÿåˆæ˜¯å› ä¸ºç‰¹å¾é¡¹ä¸å¤Ÿå¯¼è‡´çš„ï¼Œå¯ä»¥æ·»åŠ å…¶ä»–ç‰¹å¾é¡¹æ¥è§£å†³

**2ï¼‰æ·»åŠ å¤šé¡¹å¼ç‰¹å¾**ï¼Œæ¨¡å‹è¿‡äºç®€å•æ—¶çš„å¸¸ç”¨å¥—è·¯ï¼Œä¾‹å¦‚å°†çº¿æ€§æ¨¡å‹é€šè¿‡æ·»åŠ äºŒæ¬¡é¡¹æˆ–ä¸‰æ¬¡é¡¹ä½¿æ¨¡å‹æ³›åŒ–èƒ½åŠ›æ›´å¼º

**è¿‡æ‹Ÿåˆäº§ç”ŸåŸå› ï¼š** åŸå§‹ç‰¹å¾è¿‡å¤šï¼Œå­˜åœ¨ä¸€äº›å˜ˆæ‚ç‰¹å¾ï¼Œ æ¨¡å‹è¿‡äºå¤æ‚æ˜¯å› ä¸ºæ¨¡å‹å°è¯•å»å…¼é¡¾æ‰€æœ‰æµ‹è¯•æ ·æœ¬

è§£å†³åŠæ³•ï¼š

1ï¼‰é‡æ–°æ¸…æ´—æ•°æ®ï¼Œå¯¼è‡´è¿‡æ‹Ÿåˆçš„ä¸€ä¸ªåŸå› æœ‰å¯èƒ½æ˜¯æ•°æ®ä¸çº¯ï¼Œå¦‚æœå‡ºç°äº†è¿‡æ‹Ÿåˆå°±éœ€è¦é‡æ–°æ¸…æ´—æ•°æ®ã€‚

2ï¼‰å¢å¤§æ•°æ®çš„è®­ç»ƒé‡ï¼Œè¿˜æœ‰ä¸€ä¸ªåŸå› å°±æ˜¯æˆ‘ä»¬ç”¨äºè®­ç»ƒçš„æ•°æ®é‡å¤ªå°å¯¼è‡´çš„ï¼Œè®­ç»ƒæ•°æ®å æ€»æ•°æ®çš„æ¯”ä¾‹è¿‡å°ã€‚

**3ï¼‰æ­£åˆ™åŒ–**

4ï¼‰å‡å°‘ç‰¹å¾ç»´åº¦

### ã€ç†è§£ã€‘æ­£åˆ™åŒ–

åœ¨è§£å†³å›å½’è¿‡æ‹Ÿåˆä¸­ï¼Œæˆ‘ä»¬é€‰æ‹©æ­£åˆ™åŒ–ã€‚ä½†æ˜¯å¯¹äºå…¶ä»–æœºå™¨å­¦ä¹ ç®—æ³•å¦‚åˆ†ç±»ç®—æ³•æ¥è¯´ä¹Ÿä¼šå‡ºç°è¿™æ ·çš„é—®é¢˜ï¼Œé™¤äº†ä¸€äº›ç®—æ³•æœ¬èº«ä½œç”¨ä¹‹å¤–ï¼ˆå†³ç­–æ ‘ã€ç¥ç»ç½‘ç»œï¼‰ï¼Œæˆ‘ä»¬æ›´å¤šçš„ä¹Ÿæ˜¯å»è‡ªå·±åšç‰¹å¾é€‰æ‹©ï¼ŒåŒ…æ‹¬ä¹‹å‰è¯´çš„åˆ é™¤ã€åˆå¹¶ä¸€äº›ç‰¹å¾

<img src="images/006tNbRwly1ga8u2sjcw9j314o0g8wkd.jpg" style="zoom:50%;" />

**å¦‚ä½•è§£å†³ï¼Ÿ**

<img src="images/006tNbRwly1ga8u2tduvuj30zs0kctav.jpg" alt="Ã¦Â­Â£Ã¥ÂˆÂ™Ã¥ÂŒÂ–" style="zoom: 33%;" />

**åœ¨å­¦ä¹ çš„æ—¶å€™ï¼Œæ•°æ®æä¾›çš„ç‰¹å¾æœ‰äº›å½±å“æ¨¡å‹å¤æ‚åº¦æˆ–è€…è¿™ä¸ªç‰¹å¾çš„æ•°æ®ç‚¹å¼‚å¸¸è¾ƒå¤šï¼Œæ‰€ä»¥ç®—æ³•åœ¨å­¦ä¹ çš„æ—¶å€™å°½é‡å‡å°‘è¿™ä¸ªç‰¹å¾çš„å½±å“ï¼ˆç”šè‡³åˆ é™¤æŸä¸ªç‰¹å¾çš„å½±å“ï¼‰ï¼Œè¿™å°±æ˜¯æ­£åˆ™åŒ–**

æ³¨ï¼šè°ƒæ•´æ—¶å€™ï¼Œç®—æ³•å¹¶ä¸çŸ¥é“æŸä¸ªç‰¹å¾å½±å“ï¼Œè€Œæ˜¯å»è°ƒæ•´å‚æ•°å¾—å‡ºä¼˜åŒ–çš„ç»“

#### **L1æ­£åˆ™åŒ–**

- å‡è®¾ğ¿(ğ‘Š)æ˜¯æœªåŠ æ­£åˆ™é¡¹çš„æŸå¤±ï¼Œğœ†æ˜¯ä¸€ä¸ªè¶…å‚ï¼Œæ§åˆ¶æ­£åˆ™åŒ–é¡¹çš„å¤§å°ã€‚
- åˆ™æœ€ç»ˆçš„æŸå¤±å‡½æ•°ï¼š$ğ¿=ğ¿(ğ‘Š)+ \lambda*\sum_{i=1}^{n}\lvert w_i\rvert$ 

ä½œç”¨ï¼šç”¨æ¥è¿›è¡Œç‰¹å¾é€‰æ‹©ï¼Œä¸»è¦åŸå› åœ¨äºL1æ­£åˆ™åŒ–ä¼šä½¿å¾—è¾ƒå¤šçš„å‚æ•°ä¸º0ï¼Œä»è€Œäº§ç”Ÿç¨€ç–è§£,å¯ä»¥å°†0å¯¹åº”çš„ç‰¹å¾é—å¼ƒï¼Œè¿›è€Œç”¨æ¥é€‰æ‹©ç‰¹å¾ã€‚ä¸€å®šç¨‹åº¦ä¸ŠL1æ­£åˆ™ä¹Ÿå¯ä»¥é˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆã€‚

![image-20230913145042318](images/image-20230913145042318.png)

**L1æ­£åˆ™ä¸ºä»€ä¹ˆå¯ä»¥äº§ç”Ÿç¨€ç–è§£ï¼ˆå¯ä»¥ç‰¹å¾é€‰æ‹©ï¼‰**

ç¨€ç–æ€§ï¼šå‘é‡ä¸­å¾ˆå¤šç»´åº¦å€¼ä¸º0

- å¯¹å…¶ä¸­çš„ä¸€ä¸ªå‚æ•° $ w_i $ è®¡ç®—æ¢¯åº¦ï¼Œå…¶ä»–å‚æ•°åŒç†ï¼ŒÎ±æ˜¯å­¦ä¹ ç‡ï¼Œsign(wi)æ˜¯ç¬¦å·å‡½æ•°ã€‚

<img src="images/l2_4.png" alt="l2" style="zoom:50%;" />

L1çš„æ¢¯åº¦ï¼š

$ğ¿=ğ¿(ğ‘Š)+ \lambda*\sum_{i=1}^{n}\lvert w_i\rvert$ 

$\frac{\partial L}{\partial w_{i}} = \frac{\partial L(W)}{\partial w_{i}}+\lambda sign(w_{i})$

LASSOå›å½’: from sklearn.linear_model import Lasso



#### **L2æ­£åˆ™åŒ–**

- å‡è®¾ğ¿(ğ‘Š)æ˜¯æœªåŠ æ­£åˆ™é¡¹çš„æŸå¤±ï¼Œğœ†æ˜¯ä¸€ä¸ªè¶…å‚ï¼Œæ§åˆ¶æ­£åˆ™åŒ–é¡¹çš„å¤§å°ã€‚
- åˆ™æœ€ç»ˆçš„æŸå¤±å‡½æ•°ï¼š$ğ¿=ğ¿(ğ‘Š)+ \lambda*\sum_{i=1}^{n}w_{i}^{2}$ 

ä½œç”¨ï¼šä¸»è¦ç”¨æ¥é˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆï¼Œå¯ä»¥å‡å°ç‰¹å¾çš„æƒé‡

ä¼˜ç‚¹ï¼šè¶Šå°çš„å‚æ•°è¯´æ˜æ¨¡å‹è¶Šç®€å•ï¼Œè¶Šç®€å•çš„æ¨¡å‹åˆ™è¶Šä¸å®¹æ˜“äº§ç”Ÿè¿‡æ‹Ÿåˆç°è±¡

Ridgeå›å½’: from sklearn.linear_model import Ridge





#### **æ­£åˆ™åŒ–æ¡ˆä¾‹**

```python
X10 = np.hstack([X2,X**3,X**4,X**5,X**6,X**7,X**8,X**9,X**10]) 
estimator3 = LinearRegression() 
estimator3.fit(X10,y) 
y_predict3 = estimator3.predict(X10) 

plt.scatter(x,y) 
plt.plot(np.sort(x),y_predict3[np.argsort(x)],color = 'r') 
plt.show()

estimator3.coef_

array([ 1.32292089e+00,  2.03952017e+00, -2.88731664e-01, -1.24760429e+00,
        8.06147066e-02,  3.72878513e-01, -7.75395040e-03, -4.64121137e-02,
        1.84873446e-04,  2.03845917e-03])
```

![img](images/l2_5.png)

```python
from sklearn.linear_model import Lasso  # L1æ­£åˆ™
from sklearn.linear_model import Ridge  # å²­å›å½’ L2æ­£åˆ™

def dm04_æ¨¡å‹è¿‡æ‹Ÿåˆ_L1æ­£åˆ™åŒ–():
    # 1. å‡†å¤‡x, yæ•°æ®, å¢åŠ ä¸Šå™ªå£°.
    # ç”¨äºè®¾ç½®éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­ï¼ˆseedï¼‰, ç§å­ä¸€æ ·, æ¯æ¬¡ç”Ÿæˆç›¸åŒåºåˆ—.
    np.random.seed(666)
    # x: éšæœºæ•°, èŒƒå›´ä¸º (-3, 3), 100ä¸ª.
    x = np.random.uniform(-3, 3, size=100)
    # loc: å‡å€¼, scale: æ ‡å‡†å·®, normal: æ­£æ€åˆ†å¸ƒ.
    y = 0.5 * x ** 2 + x + 2 + np.random.normal(0, 1, size=100)
    # 2. å®ä¾‹åŒ–L1æ­£åˆ™åŒ–æ¨¡å‹, åšå®éªŒ: alphaæƒ©ç½šåŠ›åº¦è¶Šæ¥è¶Šå¤§, kå€¼è¶Šæ¥è¶Šå°.
    estimator = Lasso(alpha=0.005)
    # 3. è®­ç»ƒæ¨¡å‹
    X = x.reshape(-1, 1)
    # hstack() å‡½æ•°ç”¨äºå°†å¤šä¸ªæ•°ç»„åœ¨è¡Œä¸Šå †å èµ·æ¥, å³: æ•°æ®å¢åŠ é«˜æ¬¡é¡¹.
    X3 = np.hstack([X, X**2, X**3, X**4, X**5, X**6, X**7, X**8, X**9, X**10])
    estimator.fit(X3, y)
    print(f'æƒé‡: {estimator.coef_}')

    # 4. æ¨¡å‹é¢„æµ‹.
    y_predict = estimator.predict(X3)
    print("é¢„æµ‹å€¼:", y_predict)

    # 5. è®¡ç®—å‡æ–¹è¯¯å·® => æ¨¡å‹è¯„ä¼°
    print(f'å‡æ–¹è¯¯å·®: {mean_squared_error(y, y_predict)}')
    # 6. ç”»å›¾
    plt.scatter(x, y)  # æ•£ç‚¹å›¾
    # sort()  è¯¥å‡½æ•°ç›´æ¥è¿”å›ä¸€ä¸ªæ’åºåçš„æ–°æ•°ç»„ã€‚
    # numpy.argsort()   è¯¥å‡½æ•°è¿”å›çš„æ˜¯æ•°ç»„å€¼ä»å°åˆ°å¤§æ’åºæ—¶å¯¹åº”çš„ç´¢å¼•å€¼
    plt.plot(np.sort(x), y_predict[np.argsort(x)], color='r')  # æŠ˜çº¿å›¾(é¢„æµ‹å€¼, æ‹Ÿåˆå›å½’çº¿)
    plt.show()  # å…·ä½“çš„ç»˜å›¾
```

![img](images/l2_6.png)

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression, Lasso, Ridge
from sklearn.metrics import mean_squared_error  # è®¡ç®—å‡æ–¹è¯¯å·®
from sklearn.model_selection import train_test_split


def dm01_æ¬ æ‹Ÿåˆ():
    # 1. å‡†å¤‡x, yæ•°æ®, å¢åŠ ä¸Šå™ªå£°.
    # ç”¨äºè®¾ç½®éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­ï¼ˆseedï¼‰, ç§å­ä¸€æ ·, æ¯æ¬¡ç”Ÿæˆç›¸åŒåºåˆ—.
    np.random.seed(666)
    # x: éšæœºæ•°, èŒƒå›´ä¸º (-3, 3), 100ä¸ª.
    x = np.random.uniform(-3, 3, size=100)
    # loc: å‡å€¼, scale: æ ‡å‡†å·®, normal: æ­£æ€åˆ†å¸ƒ.
    y = 0.5 * x ** 2 + x + 2 + np.random.normal(0, 1, size=100)
    # 2. å®ä¾‹åŒ– çº¿æ€§å›å½’æ¨¡å‹.
    estimator = LinearRegression()
    # 3. è®­ç»ƒæ¨¡å‹
    X = x.reshape(-1, 1)
    estimator.fit(X, y)

    # 4. æ¨¡å‹é¢„æµ‹.
    y_predict = estimator.predict(X)
    print("é¢„æµ‹å€¼:", y_predict)

    # 5. è®¡ç®—å‡æ–¹è¯¯å·® => æ¨¡å‹è¯„ä¼°
    print(f'å‡æ–¹è¯¯å·®: {mean_squared_error(y, y_predict)}')
    # 6. ç”»å›¾
    plt.scatter(x, y)           # æ•£ç‚¹å›¾
    plt.plot(x, y_predict, color='r')   # æŠ˜çº¿å›¾(é¢„æµ‹å€¼, æ‹Ÿåˆå›å½’çº¿)
    plt.show()                  # å…·ä½“çš„ç»˜å›¾

def dm02_æ¨¡å‹ok():
    # 1. å‡†å¤‡x, yæ•°æ®, å¢åŠ ä¸Šå™ªå£°.
    # ç”¨äºè®¾ç½®éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­ï¼ˆseedï¼‰, ç§å­ä¸€æ ·, æ¯æ¬¡ç”Ÿæˆç›¸åŒåºåˆ—.
    np.random.seed(666)
    # x: éšæœºæ•°, èŒƒå›´ä¸º (-3, 3), 100ä¸ª.
    x = np.random.uniform(-3, 3, size=100)
    # loc: å‡å€¼, scale: æ ‡å‡†å·®, normal: æ­£æ€åˆ†å¸ƒ.
    y = 0.5 * x ** 2 + x + 2 + np.random.normal(0, 1, size=100)
    # 2. å®ä¾‹åŒ– çº¿æ€§å›å½’æ¨¡å‹.
    estimator = LinearRegression()
    # 3. è®­ç»ƒæ¨¡å‹
    X = x.reshape(-1, 1)
    X2 = np.hstack([X, X ** 2])
    estimator.fit(X2, y)

    # 4. æ¨¡å‹é¢„æµ‹.
    y_predict = estimator.predict(X2)
    print("é¢„æµ‹å€¼:", y_predict)

    # 5. è®¡ç®—å‡æ–¹è¯¯å·® => æ¨¡å‹è¯„ä¼°
    print(f'å‡æ–¹è¯¯å·®: {mean_squared_error(y, y_predict)}')
    # 6. ç”»å›¾
    plt.scatter(x, y)  # æ•£ç‚¹å›¾
    # sort()  è¯¥å‡½æ•°ç›´æ¥è¿”å›ä¸€ä¸ªæ’åºåçš„æ–°æ•°ç»„ã€‚
    # numpy.argsort()   è¯¥å‡½æ•°è¿”å›çš„æ˜¯æ•°ç»„å€¼ä»å°åˆ°å¤§æ’åºæ—¶å¯¹åº”çš„ç´¢å¼•å€¼
    plt.plot(np.sort(x), y_predict[np.argsort(x)], color='r')  # æŠ˜çº¿å›¾(é¢„æµ‹å€¼, æ‹Ÿåˆå›å½’çº¿)
    # plt.plot(x, y_predict)
    plt.show()  # å…·ä½“çš„ç»˜å›¾

def dm03_è¿‡æ‹Ÿåˆ():
    # 1. å‡†å¤‡x, yæ•°æ®, å¢åŠ ä¸Šå™ªå£°.
    # ç”¨äºè®¾ç½®éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­ï¼ˆseedï¼‰, ç§å­ä¸€æ ·, æ¯æ¬¡ç”Ÿæˆç›¸åŒåºåˆ—.
    np.random.seed(666)
    # x: éšæœºæ•°, èŒƒå›´ä¸º (-3, 3), 100ä¸ª.
    x = np.random.uniform(-3, 3, size=100)
    # loc: å‡å€¼, scale: æ ‡å‡†å·®, normal: æ­£æ€åˆ†å¸ƒ.
    y = 0.5 * x ** 2 + x + 2 + np.random.normal(0, 1, size=100)
    # 2. å®ä¾‹åŒ– çº¿æ€§å›å½’æ¨¡å‹.
    estimator = LinearRegression()
    # 3. è®­ç»ƒæ¨¡å‹
    X = x.reshape(-1, 1)
    # hstack() å‡½æ•°ç”¨äºå°†å¤šä¸ªæ•°ç»„åœ¨è¡Œä¸Šå †å èµ·æ¥, å³: æ•°æ®å¢åŠ é«˜æ¬¡é¡¹.
    X3 = np.hstack([X, X**2, X**3, X**4, X**5, X**6, X**7, X**8, X**9, X**10])
    estimator.fit(X3, y)

    # 4. æ¨¡å‹é¢„æµ‹.
    y_predict = estimator.predict(X3)
    print("é¢„æµ‹å€¼:", y_predict)

    # 5. è®¡ç®—å‡æ–¹è¯¯å·® => æ¨¡å‹è¯„ä¼°
    print(f'å‡æ–¹è¯¯å·®: {mean_squared_error(y, y_predict)}')
    # 6. ç”»å›¾
    plt.scatter(x, y)  # æ•£ç‚¹å›¾
    # sort()  è¯¥å‡½æ•°ç›´æ¥è¿”å›ä¸€ä¸ªæ’åºåçš„æ–°æ•°ç»„ã€‚
    # numpy.argsort()   è¯¥å‡½æ•°è¿”å›çš„æ˜¯æ•°ç»„å€¼ä»å°åˆ°å¤§æ’åºæ—¶å¯¹åº”çš„ç´¢å¼•å€¼
    plt.plot(np.sort(x), y_predict[np.argsort(x)], color='r')  # æŠ˜çº¿å›¾(é¢„æµ‹å€¼, æ‹Ÿåˆå›å½’çº¿)
    plt.show()  # å…·ä½“çš„ç»˜å›¾


def dm04_æ¨¡å‹è¿‡æ‹Ÿåˆ_L1æ­£åˆ™åŒ–():
    # 1. å‡†å¤‡x, yæ•°æ®, å¢åŠ ä¸Šå™ªå£°.
    # ç”¨äºè®¾ç½®éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­ï¼ˆseedï¼‰, ç§å­ä¸€æ ·, æ¯æ¬¡ç”Ÿæˆç›¸åŒåºåˆ—.
    np.random.seed(666)
    # x: éšæœºæ•°, èŒƒå›´ä¸º (-3, 3), 100ä¸ª.
    x = np.random.uniform(-3, 3, size=100)
    # loc: å‡å€¼, scale: æ ‡å‡†å·®, normal: æ­£æ€åˆ†å¸ƒ.
    y = 0.5 * x ** 2 + x + 2 + np.random.normal(0, 1, size=100)
    # 2. å®ä¾‹åŒ–L1æ­£åˆ™åŒ–æ¨¡å‹, åšå®éªŒ: alphaæƒ©ç½šåŠ›åº¦è¶Šæ¥è¶Šå¤§, kå€¼è¶Šæ¥è¶Šå°.
    estimator = Lasso(alpha=0.005)
    # 3. è®­ç»ƒæ¨¡å‹
    X = x.reshape(-1, 1)
    # hstack() å‡½æ•°ç”¨äºå°†å¤šä¸ªæ•°ç»„åœ¨è¡Œä¸Šå †å èµ·æ¥, å³: æ•°æ®å¢åŠ é«˜æ¬¡é¡¹.
    X3 = np.hstack([X, X**2, X**3, X**4, X**5, X**6, X**7, X**8, X**9, X**10])
    estimator.fit(X3, y)
    print(f'æƒé‡: {estimator.coef_}')

    # 4. æ¨¡å‹é¢„æµ‹.
    y_predict = estimator.predict(X3)
    print("é¢„æµ‹å€¼:", y_predict)

    # 5. è®¡ç®—å‡æ–¹è¯¯å·® => æ¨¡å‹è¯„ä¼°
    print(f'å‡æ–¹è¯¯å·®: {mean_squared_error(y, y_predict)}')
    # 6. ç”»å›¾
    plt.scatter(x, y)  # æ•£ç‚¹å›¾
    # sort()  è¯¥å‡½æ•°ç›´æ¥è¿”å›ä¸€ä¸ªæ’åºåçš„æ–°æ•°ç»„ã€‚
    # numpy.argsort()   è¯¥å‡½æ•°è¿”å›çš„æ˜¯æ•°ç»„å€¼ä»å°åˆ°å¤§æ’åºæ—¶å¯¹åº”çš„ç´¢å¼•å€¼
    plt.plot(np.sort(x), y_predict[np.argsort(x)], color='r')  # æŠ˜çº¿å›¾(é¢„æµ‹å€¼, æ‹Ÿåˆå›å½’çº¿)
    plt.show()  # å…·ä½“çš„ç»˜å›¾

def dm05_æ¨¡å‹è¿‡æ‹Ÿåˆ_L2æ­£åˆ™åŒ–():
    # 1. å‡†å¤‡x, yæ•°æ®, å¢åŠ ä¸Šå™ªå£°.
    # ç”¨äºè®¾ç½®éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­ï¼ˆseedï¼‰, ç§å­ä¸€æ ·, æ¯æ¬¡ç”Ÿæˆç›¸åŒåºåˆ—.
    np.random.seed(666)
    # x: éšæœºæ•°, èŒƒå›´ä¸º (-3, 3), 100ä¸ª.
    x = np.random.uniform(-3, 3, size=100)
    # loc: å‡å€¼, scale: æ ‡å‡†å·®, normal: æ­£æ€åˆ†å¸ƒ.
    y = 0.5 * x ** 2 + x + 2 + np.random.normal(0, 1, size=100)
    # 2. å®ä¾‹åŒ–L2æ­£åˆ™åŒ–æ¨¡å‹, åšå®éªŒ: alphaæƒ©ç½šåŠ›åº¦è¶Šæ¥è¶Šå¤§, kå€¼è¶Šæ¥è¶Šå°.
    estimator = Ridge(alpha=0.005)
    # 3. è®­ç»ƒæ¨¡å‹
    X = x.reshape(-1, 1)
    # hstack() å‡½æ•°ç”¨äºå°†å¤šä¸ªæ•°ç»„åœ¨è¡Œä¸Šå †å èµ·æ¥, å³: æ•°æ®å¢åŠ é«˜æ¬¡é¡¹.
    X3 = np.hstack([X, X**2, X**3, X**4, X**5, X**6, X**7, X**8, X**9, X**10])
    estimator.fit(X3, y)
    print(f'æƒé‡: {estimator.coef_}')

    # 4. æ¨¡å‹é¢„æµ‹.
    y_predict = estimator.predict(X3)
    print("é¢„æµ‹å€¼:", y_predict)

    # 5. è®¡ç®—å‡æ–¹è¯¯å·® => æ¨¡å‹è¯„ä¼°
    print(f'å‡æ–¹è¯¯å·®: {mean_squared_error(y, y_predict)}')
    # 6. ç”»å›¾
    plt.scatter(x, y)  # æ•£ç‚¹å›¾
    # sort()  è¯¥å‡½æ•°ç›´æ¥è¿”å›ä¸€ä¸ªæ’åºåçš„æ–°æ•°ç»„ã€‚
    # numpy.argsort()   è¯¥å‡½æ•°è¿”å›çš„æ˜¯æ•°ç»„å€¼ä»å°åˆ°å¤§æ’åºæ—¶å¯¹åº”çš„ç´¢å¼•å€¼
    plt.plot(np.sort(x), y_predict[np.argsort(x)], color='r')  # æŠ˜çº¿å›¾(é¢„æµ‹å€¼, æ‹Ÿåˆå›å½’çº¿)
    plt.show()  # å…·ä½“çš„ç»˜å›¾

if __name__ == '__main__':
    # dm01_æ¬ æ‹Ÿåˆ()
    # dm02_æ¨¡å‹ok()
    dm03_è¿‡æ‹Ÿåˆ()
    # dm04_æ¨¡å‹è¿‡æ‹Ÿåˆ_L1æ­£åˆ™åŒ–()
    # dm05_æ¨¡å‹è¿‡æ‹Ÿåˆ_L2æ­£åˆ™åŒ–()

```

![img](images/l2_7.png)









## ä½œä¸š

1.å®Œæˆçº¿æ€§å›å½’éƒ¨åˆ†çš„æ€ç»´å¯¼å›¾



2.æè¿°æ¢¯åº¦ä¸‹é™ç®—æ³•æ€æƒ³ï¼Œè‡ªå·±æ¨å¯¼é“¶è¡Œä¿¡è´·çš„æ¡ˆä¾‹





3.è¯´æ˜æ¬ æ‹Ÿåˆå’Œè¿‡æ‹Ÿåˆçš„ç›¸å…³å†…å®¹



3.ä½¿ç”¨L1å’ŒL2æ­£åˆ™åŒ–æ–¹æ³•å®ç°æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹

















