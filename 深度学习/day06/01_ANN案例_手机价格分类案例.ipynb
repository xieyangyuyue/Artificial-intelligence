{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c2dde7-cfee-47fd-b16a-14b913634043",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "案例:\n",
    "    ANN(人工神经网络)案例: 手机价格分类案例.\n",
    "\n",
    "背景:\n",
    "    基于手机的20列特征 -> 预测手机的价格区间(4个区间), 可以用机器学习做, 也可以用 深度学习做(推荐)\n",
    "\n",
    "ANN案例的实现步骤:\n",
    "    1. 构建数据集.\n",
    "    2. 搭建神经网络.\n",
    "    3. 模型训练.\n",
    "    4. 模型测试.\n",
    "\n",
    "优化思路:\n",
    "    1. 优化方法从 SGD -> Adam\n",
    "    2. 学习率从 0.001 -> 0.0001\n",
    "    3. 对数据进行标准化.\n",
    "    4. 增加网络的深度, 每层的神经元数量\n",
    "    5. 调整训练的轮数\n",
    "    6. ......\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baac88f2-5ef9-425e-91ed-7943f63f0bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 导包\n",
    "import torch                                    # PyTorch框架, 封装了张量的各种操作\n",
    "from torch.utils.data import TensorDataset      # 数据集对象.   数据 -> Tensor -> 数据集 -> 数据加载器\n",
    "from torch.utils.data import DataLoader         # 数据加载器.\n",
    "import torch.nn as nn                           # neural network, 封装了神经网络的各种操作\n",
    "import torch.optim as optim                     # 优化器\n",
    "from sklearn.model_selection import train_test_split    # 训练集和测试集的划分\n",
    "import matplotlib.pyplot as plt                 # 绘图\n",
    "import numpy as np                              # 数组(矩阵)操作\n",
    "import pandas as pd                             # 数据处理\n",
    "import time                                     # 时间模块\n",
    "from torchsummary import summary                # 模型结构可视化\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d27feae-3a41-49f7-89b8-5d85db4a9fb8",
   "metadata": {},
   "source": [
    "# todo 1. 定义函数, 构建数据集."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad876f20-71b2-429c-ac49-3813514195a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    # 1. 加载csv文件数据集.\n",
    "    data = pd.read_csv('./data/手机价格预测.csv')\n",
    "    # print(f'data: {data.head()}')\n",
    "    # print(f'data: {data.shape}')    # (2000, 21)\n",
    "\n",
    "    # 2. 获取x特征列 和 y标签列.\n",
    "    x, y = data.iloc[:, :-1], data.iloc[:, -1]\n",
    "    # print(f'x: {x.head()}, {x.shape}')  # (2000, 20)\n",
    "    # print(f'y: {y.head()}, {y.shape}')  # (2000, )\n",
    "\n",
    "    # 3. 把特征列转成浮点型.\n",
    "    x = x.astype(np.float32)\n",
    "    # print(f'x: {x.head()}, {x.shape}')   # (2000, 20)\n",
    "\n",
    "    # 4. 切分训练集和测试集.\n",
    "    # 参1: 特征, 参2: 标签, 参3: 测试集所占比例, 参4: 随机种子, 参5: 样本的分布(即: 参考y的类别进行抽取数据)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=3, stratify=y)\n",
    "\n",
    "    # 5. 把数据集封装成 张量数据集.  思路: 数据 -> 张量Tensor -> 数据集TensorDataSet -> 数据加载器DataLoader\n",
    "    train_dataset = TensorDataset(torch.tensor(x_train.values), torch.tensor(y_train.values))\n",
    "    test_dataset = TensorDataset(torch.tensor(x_test.values), torch.tensor(y_test.values))\n",
    "    # print(f'train_dataset: {train_dataset}, test_dataset: {test_dataset}')\n",
    "\n",
    "    # 6. 返回结果                         20(充当 输入特征数)     4(充当 输出标签数)\n",
    "    return train_dataset, test_dataset, x_train.shape[1], len(np.unique(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bed561c-15b3-4b8d-9b15-858a4a656a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集 数据集对象: <torch.utils.data.dataset.TensorDataset object at 0x7f073e967be0>\n",
      "测试集 数据集对象: <torch.utils.data.dataset.TensorDataset object at 0x7f073e982100>\n",
      "输入特征数: 20\n",
      "输出标签数: 4\n"
     ]
    }
   ],
   "source": [
    "    # 1. 准备数据集.\n",
    "    train_dataset, test_dataset, input_dim, output_dim = create_dataset()\n",
    "    print(f'训练集 数据集对象: {train_dataset}')\n",
    "    print(f'测试集 数据集对象: {test_dataset}')\n",
    "    print(f'输入特征数: {input_dim}')    # 20\n",
    "    print(f'输出标签数: {output_dim}')   # 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99b4b78-0dae-4bc1-bb0d-37449f05982d",
   "metadata": {},
   "source": [
    "\n",
    "# todo 2. 搭建神经网络."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8ae9725-107a-47df-8979-e3e4e8cdcd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhonePriceModel(nn.Module):\n",
    "    # 1. 在init魔法方法中, 初始化父类成员, 及搭建神经网络.\n",
    "    def __init__(self, input_dim, output_dim):  # 输入: 20, 输出: 4\n",
    "        # 1.1 初始化父类成员.\n",
    "        super().__init__()\n",
    "        # 1.2 搭建神经网络.\n",
    "        # 隐藏层1\n",
    "        self.linear1 = nn.Linear(input_dim, 128)\n",
    "        # 隐藏层2\n",
    "        self.linear2 = nn.Linear(128, 256)\n",
    "        # 输出层\n",
    "        self.output = nn.Linear(256, output_dim)\n",
    "\n",
    "\n",
    "    # 2. 定义前向传播方法 forward()\n",
    "    def forward(self, x):\n",
    "        # 2.1 隐藏层1: 加权求和 + 激活函数(relu)\n",
    "        # x = self.linear1(x)\n",
    "        # x = torch.relu(x)\n",
    "        x = torch.relu(self.linear1(x))\n",
    "        # 2.2 隐藏层2: 加权求和 + 激活函数(relu)\n",
    "        x = torch.relu(self.linear2(x))\n",
    "        # 2.3 输出层: 加权求和 + 激活函数(softmax)  -> 这里只需要做 加权求和.\n",
    "        # 正常写法, 但是不需要, 后续用 多分类交叉熵损失函数 CrossEntropyLoss() 替代\n",
    "        # CrossEntropyLoss() = softmax() + 损失计算\n",
    "        # x = torch.softmax(self.output(x), dim=1)\n",
    "        x = self.output(x)\n",
    "        # 2.4 返回处理结果\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68bc7f0d-97d9-41bb-a872-4e635aad007e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1              [-1, 16, 128]           2,688\n",
      "            Linear-2              [-1, 16, 256]          33,024\n",
      "            Linear-3                [-1, 16, 4]           1,028\n",
      "================================================================\n",
      "Total params: 36,740\n",
      "Trainable params: 36,740\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 0.14\n",
      "Estimated Total Size (MB): 0.19\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "    # 2. 构建神经网络模型.\n",
    "    model = PhonePriceModel(input_dim, output_dim)\n",
    "    # 计算模型参数\n",
    "    # 参1: 模型对象. 参2: 输入数据的形状(批次大小, 输入特征数), 每批16条, 每条20列特征\n",
    "    summary(model, input_size=(16, input_dim))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a578dfc-2e3b-4163-814d-bf7b9b77845a",
   "metadata": {},
   "source": [
    "# todo 3. 模型训练."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3f1831b-ce0d-417e-9b49-26533452216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo 3. 模型训练.\n",
    "def train(train_dataset, input_dim, output_dim):\n",
    "    # 1. 创建数据加载器, 流程: 数据 -> 张量 -> 数据集 -> 数据加载器\n",
    "    # 参1: 数据集对象(1600条), 参2: 每批次的数据条数, 参3: 是否打乱数据(训练集: 打乱, 测试集: 不打乱)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    # 2. 创建神经网络模型.\n",
    "    model = PhonePriceModel(input_dim, output_dim)\n",
    "    # 3. 定义损失函数, 因为是多分类, 这里用的是: 多分类交叉熵损失函数.\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # 4. 创建优化器对象.\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "    # 5. 模型训练.\n",
    "    # 5.1 定义变量, 记录训练的 总轮数.\n",
    "    epochs = 50\n",
    "    # 5.2 开始(每轮的)训练.\n",
    "    for epoch in range(epochs):\n",
    "        # 5.2.1 定义变量, 记录每次训练的损失值, 训练批次数.\n",
    "        total_loss, batch_num = 0.0, 0\n",
    "        # 5.2.2 定义变量, 表示训练开始的时间.\n",
    "        start = time.time()\n",
    "        # 5.2.3 开始本轮的 各个批次的训练.\n",
    "        for x, y in train_loader:\n",
    "            # 5.2.4 切换模型(状态)\n",
    "            model.train()   # 训练模式.    model.eval()   # 测试模式.\n",
    "            # 5.2.5 模型预测.\n",
    "            y_pred = model(x)\n",
    "            # 5.2.6 计算损失.\n",
    "            loss = criterion(y_pred, y)\n",
    "            # 5.2.7 梯度清零, 反向传播, 优化参数.\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # 5.2.8 累加损失值.\n",
    "            total_loss += loss.item()   # 把本轮的每批次(16条)的 平均损失累计起来. 第1批次的平均损失 + 第2批次的平均损失 + ...\n",
    "            batch_num += 1\n",
    "        # 5.2.4 至此, 本轮训练结束, 打印训练信息.\n",
    "        print(f'epoch: {epoch + 1}, loss: {total_loss / batch_num:.4f}, time: {time.time() - start:.2f}s')\n",
    "\n",
    "    # 6. 走到这里, 说明多轮训练结束, 保存模型(参数)\n",
    "    # 参1: 模型对象的参数(权重矩阵, 偏置矩阵)  参2: 模型保存的文件名.\n",
    "    # print(f'\\n\\n模型的参数信息: {model.state_dict()}\\n\\n')\n",
    "    torch.save(model.state_dict(), './model/phone.pth') # 后缀名用: pth, pkl, pickle均可."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f140ed2-c8b6-4dcf-a4b8-39c29d26d982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 20.7299, time: 0.17s\n",
      "epoch: 2, loss: 1.0025, time: 0.16s\n",
      "epoch: 3, loss: 0.9725, time: 0.16s\n",
      "epoch: 4, loss: 0.9488, time: 0.16s\n",
      "epoch: 5, loss: 0.9127, time: 0.17s\n",
      "epoch: 6, loss: 0.9301, time: 0.16s\n",
      "epoch: 7, loss: 0.9354, time: 0.17s\n",
      "epoch: 8, loss: 0.8875, time: 0.16s\n",
      "epoch: 9, loss: 0.8599, time: 0.16s\n",
      "epoch: 10, loss: 0.8522, time: 0.16s\n",
      "epoch: 11, loss: 0.8366, time: 0.18s\n",
      "epoch: 12, loss: 0.8420, time: 0.17s\n",
      "epoch: 13, loss: 0.8287, time: 0.16s\n",
      "epoch: 14, loss: 0.8294, time: 0.19s\n",
      "epoch: 15, loss: 0.8305, time: 0.17s\n",
      "epoch: 16, loss: 0.8457, time: 0.17s\n",
      "epoch: 17, loss: 0.8602, time: 0.17s\n",
      "epoch: 18, loss: 0.8198, time: 0.16s\n",
      "epoch: 19, loss: 0.7982, time: 0.16s\n",
      "epoch: 20, loss: 0.7953, time: 0.16s\n",
      "epoch: 21, loss: 0.8050, time: 0.16s\n",
      "epoch: 22, loss: 0.8111, time: 0.17s\n",
      "epoch: 23, loss: 0.7902, time: 0.17s\n",
      "epoch: 24, loss: 0.7670, time: 0.16s\n",
      "epoch: 25, loss: 0.7622, time: 0.16s\n",
      "epoch: 26, loss: 0.7869, time: 0.16s\n",
      "epoch: 27, loss: 0.7957, time: 0.17s\n",
      "epoch: 28, loss: 0.7551, time: 0.16s\n",
      "epoch: 29, loss: 0.7678, time: 0.16s\n",
      "epoch: 30, loss: 0.7631, time: 0.16s\n",
      "epoch: 31, loss: 0.7646, time: 0.16s\n",
      "epoch: 32, loss: 0.7629, time: 0.16s\n",
      "epoch: 33, loss: 0.7755, time: 0.16s\n",
      "epoch: 34, loss: 0.7501, time: 0.16s\n",
      "epoch: 35, loss: 0.8018, time: 0.17s\n",
      "epoch: 36, loss: 0.7577, time: 0.18s\n",
      "epoch: 37, loss: 0.7521, time: 0.16s\n",
      "epoch: 38, loss: 0.7275, time: 0.17s\n",
      "epoch: 39, loss: 0.7581, time: 0.16s\n",
      "epoch: 40, loss: 0.7024, time: 0.16s\n",
      "epoch: 41, loss: 0.7183, time: 0.17s\n",
      "epoch: 42, loss: 0.7335, time: 0.17s\n",
      "epoch: 43, loss: 0.7473, time: 0.17s\n",
      "epoch: 44, loss: 0.7433, time: 0.18s\n",
      "epoch: 45, loss: 0.7562, time: 0.19s\n",
      "epoch: 46, loss: 0.7215, time: 0.18s\n",
      "epoch: 47, loss: 0.7357, time: 0.17s\n",
      "epoch: 48, loss: 0.7088, time: 0.17s\n",
      "epoch: 49, loss: 0.7193, time: 0.16s\n",
      "epoch: 50, loss: 0.7077, time: 0.16s\n"
     ]
    }
   ],
   "source": [
    "    # 3. 模型训练\n",
    "    train(train_dataset, input_dim, output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97f91bf3-3977-4a09-a025-55105266b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo 4. 模型测试.\n",
    "def evaluate(test_dataset, input_dim, output_dim):\n",
    "    # 1. 创建神经网络分类对象.\n",
    "    model = PhonePriceModel(input_dim, output_dim)\n",
    "    # 2. 加载模型参数.\n",
    "    model.load_state_dict(torch.load('./model/phone.pth'))\n",
    "    # 3. 创建测试集的 数据加载器对象.\n",
    "    # 参1: 数据集对象(400条), 参2: 每批次的数据条数, 参3: 是否打乱数据(训练集: 打乱, 测试集: 不打乱)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "    # 4. 定义变量, 记录预测正确的样本个数.\n",
    "    correct = 0\n",
    "    # 5. 从数据加载器中, 获取到每批次的数据.\n",
    "    for x, y in test_loader:\n",
    "        # 5.1 切换模型状态 -> 测试模式.\n",
    "        model.eval()\n",
    "        # 5.2 模型预测.\n",
    "        y_pred = model(x)\n",
    "        # print(f'y_pred: {y_pred}')  # [[0分类概率, 1分类概率, 2分类概率, 3分类概率], [...]...]\n",
    "\n",
    "        # 5.3 根据加权求和, 得到类别, 用argmax()获取最大值对应的下标, 就是类别.\n",
    "        y_pred = torch.argmax(y_pred, dim=1)    # dim=1 表示逐行处理.\n",
    "        # print(f'y_pred: {y_pred}')  # [第1条数据的预测分类, ...]\n",
    "        # print(f'y: {y}')\n",
    "\n",
    "        # 5.4 统计预测正确的样本个数.\n",
    "        # print(y_pred == y)          # tensor([ True,  True,  True,  True, False, False,  True, False])\n",
    "        # print((y_pred == y).sum())  # True:1, False:0\n",
    "        correct += (y_pred == y).sum()\n",
    "\n",
    "    # 6.走到这里, 模型预测结束, 打印准确率即可.\n",
    "    print(f'准确率(Accuracy): {correct / len(test_dataset):.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6232a76-4b54-4fd5-8f74-092bad2b591e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率(Accuracy): 0.6850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19612/618559105.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('./model/phone.pth'))\n"
     ]
    }
   ],
   "source": [
    "    # 4. 模型测试.\n",
    "    evaluate(test_dataset, input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13289c8-a5d0-485a-9904-20df40ecc596",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
