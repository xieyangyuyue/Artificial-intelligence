{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir(r'D:\\workspace\\ai_23_work_bj\\pandasProject')   # 修改相对路径的位置.\n",
    "# os.getcwd()\n",
    "\n",
    "# 解决中文显示问题，下面的代码只需运行一次即可\n",
    "import matplotlib as plt\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']    # 如果是Mac本, 不支持SimHei的时候, 可以修改为 'Microsoft YaHei' 或者 'Arial Unicode MS'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Pandas进阶语法_缺失值处理"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c90355d6d88957a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 思路1: 删除缺失值"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c92ec99fd3f74eef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. 读取数据.\n",
    "movie_df = pd.read_csv('./data/movie.csv')\n",
    "movie_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8245b1a2717fc207"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2. 查看下数据的介绍.\n",
    "movie_df.columns        # 所有的列名\n",
    "movie_df.info()         # 查看数据的 基本信息(列名, 数据类型, 非缺失值数量等)\n",
    "movie_df.describe()     # 查看数据的 描述性统计信息(均值, 中位数, 标准差等)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15f0f1e8d6a21093"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3. 删除缺失值\n",
    "# movie_df.dropna()   # 不会修改原数据, 加入 inplace=True 即可, 默认删: axis=0, 删行, axis=1, 删列.\n",
    "\n",
    "# movie_df.dropna(axis=0)     # 删行\n",
    "movie_df.dropna(axis=1)      # 删列"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43a28dbc2fb65a7d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 思路2: 填充缺失值"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2d56e6a6db5c800"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. 查看源数据\n",
    "movie_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be9147733c06fc53"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2. 判断某列(的某个值)是否有缺失值. \n",
    "pd.isnull(movie_df)     # 判断df对象的 每列的 每个值 是否为空(缺失值)\n",
    "pd.notnull(movie_df)    # 判断df对象的 每列的 每个值 是否不为空(非缺失值)\n",
    "\n",
    "# 3.判断某列是否是 包含缺失值的列. \n",
    "np.all(pd.notnull(movie_df))    # 整列都是True -> 结果是True, 但凡有False -> 结果是False, 说明该列有缺失."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb95b188f993421f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 4. 填充缺失值.\n",
    "# 写法1: 填充固定值.\n",
    "movie_df.fillna(23).info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b099b6aa4aec1781"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 写法2: 填充 每列的平均值.\n",
    "movie_df['Revenue (Millions)'].fillna(movie_df['Revenue (Millions)'].mean(), inplace=True)\n",
    "movie_df['Metascore'].fillna(movie_df['Metascore'].mean(), inplace=True)\n",
    "movie_df.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "927fab17c039fd79"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5. for循环的方式, 使用 每列的平均值 来填充各列的缺失值. \n",
    "# 5.1 获取每个列名\n",
    "for col_name in movie_df.columns:\n",
    "    # 5.2 判断某列是否有缺失值.\n",
    "    # movie_df[col_name]:  根据列名, 找到 df中的某个列 -> Series对象.\n",
    "    # pd.notnull(某列数据): 判断该列的每个值是否为非缺失值, True -> 不为空, False -> 为空(缺失值)\n",
    "    # np.all([True, False...]): 里边的值全部为True -> 结果为True, 只要有一个为False -> 结果为False.\n",
    "    if np.all(pd.notnull(movie_df[col_name])) == False:\n",
    "        # 5.3 走到这里, 说明该列有缺失值.\n",
    "        print(col_name)     # 打印列名\n",
    "        # 5.4 打印这两列的平均值. \n",
    "        print(movie_df[col_name].mean())\n",
    "        # 5.5 用该列的平均值来填充该列的缺失值.\n",
    "        movie_df[col_name].fillna(movie_df[col_name].mean(), inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5252a858416c351"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 6. 查看处理后的结果.\n",
    "movie_df.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2463d262069a26"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 思路3: 转换, 然后填充或者删除缺失值"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a587b59b3693b14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 背景: 实际开发中, 不是所有的缺失值都会用NaN来表示, 例如: 可能用 ? 表示, 如何删除这些缺失值呢? \n",
    "# 思路: 先转换, 后删除.  即:  ? -> NaN -> 删除.\n",
    "# 1. 加载数据.\n",
    "wis = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\")\n",
    "wis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ccef1748e62bc92"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2. 尝试直接删除缺失值.\n",
    "wis.dropna()        # ? 不是缺失值, 所以直接删, 删不掉. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93022ce09092f956"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3. 解决上述的问题, ? -> NaN -> 删.            空的三种写法: np.nan, np.NAN, np.NaN\n",
    "wis.replace('?', np.nan).dropna()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39043db071b031d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. 数据合并"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "634b17702f57a829"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 思路1: concat(), 能行合并, 还是列合并"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d02f587772fab05b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. 准备数据. \n",
    "df = pd.read_csv('./data/1960-2019全球GDP数据.csv', encoding='gbk')\n",
    "df\n",
    "\n",
    "df1 = df[:10]\n",
    "df1\n",
    "\n",
    "df2 = df[10:20]\n",
    "df2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "358d3333d3b907b4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2. 通过 concat() 合并数据.\n",
    "# 细节: 列合并默认参考 列名.  \n",
    "new_df = pd.concat([df1, df2], axis=0)  # axis=0, 列合并(垂直合并), axis=1, 行合并(水平合并)\n",
    "new_df = pd.concat([df1, df2])          # 效果同上, 默认是 列合并\n",
    "\n",
    "# 细节: 行合并, 默认参考 行索引(值)\n",
    "new_df = pd.concat([df1, df2], axis=1)  # 行合并\n",
    "new_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "376ab937881e8c03"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3. 修改df2的列索引.\n",
    "df2.index = [0, 1, 2, 3, 4, 11, 12, 13, 14, 15]\n",
    "df2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c70c177e0adb0846"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 4. 再次进行 行合并(参考: 行索引值)\n",
    "pd.concat([df1, df2], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c66f810707e8ce3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5. 再次进行行合并. \n",
    "# 默认是: 满外连接, 即: 左表全集 + 右表全集 + 交集\n",
    "pd.concat([df1, df2], axis=1, join='outer')    \n",
    "\n",
    "# 指定为: 内连接, 即: 只要交集\n",
    "pd.concat([df1, df2], axis=1, join='inner') \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe0645c4c99ee623"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 思路2: merge() -> 只能进行 行合并(水平合并)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc0ae5ec2c1f892e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. 准备数据集.\n",
    "df1 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
    "                        'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                        'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                        'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "\n",
    "df2 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                        'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                        'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                        'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "\n",
    "# 2. 查看数据\n",
    "df1\n",
    "df2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c81a3970fe9d562"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3. 演示 merge()函数的 默认合并方式.\n",
    "pd.merge(df1, df2, how='inner', on=['key1', 'key2'])\n",
    "pd.merge(df1, df2)      # 效果同上, 默认是 inner join, 且参考 同名列进行合并."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5044035e2e9813b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 4. 内连接, 指定合并字段\n",
    "pd.merge(df1, df2, how='inner', on='key2')  # 内连接, 关联字段为: key2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdcc6dc905921154"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5. 外连接, 指定合并字段.\n",
    "pd.merge(df1, df2, how='outer', on=['key1', 'key2'])    # 满外连接, 关联字段为: key1, key2\n",
    "\n",
    "# 左外连接 = 左表全集 + 交集\n",
    "# pd.merge(df1, df2, how='left', on=['key1', 'key2'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ac0eb2359b0cbe4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 6. merge()函数的其它写法.\n",
    "df1.merge(df2, how='inner', on='key1')      # 效果同上, 即: df1.merge(df2)\n",
    "\n",
    "# 回顾: concat写法(),   pd.concat([df1, df2...])        可以同时拼接多个, 既能行合并, 也能列合并, 不能指定合并字段. 默认是: 外连接合并方式.\n",
    "# df1.concat(df2)     # 错误写法.\n",
    "pd.concat([df1, df2, df1])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f8a75bb6275123b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. groupby() 分组聚合 以及 分组过滤"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1df51daa13cc40a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. 读取数据\n",
    "df = pd.read_csv('./data/uniqlo.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3620cb21777e6b58"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 分组聚合"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e54b19acc2ccb8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# agg -> Aggregate(聚合的意思)\n",
    "# 格式: df.groupby(['分组字段1', '分组字段2'...]).agg({'列名1':'聚合函数名', '列名2':'聚合函数名'...})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f61045066f43b584"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. 场景1: 按照单列分组\n",
    "df.groupby(['city'])        # DataFrameGroupBy  -> DataFrame分组对象\n",
    "df.groupby('city')        # 细节: 如果分组列只有1个, 中括号可以省略不写."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ed87e97595b1ae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2. 场景2: 按照多列分组\n",
    "df.groupby(['city', 'channel'])             # DataFrameGroupBy  -> DataFrame分组对象\n",
    "df.groupby(['city', 'channel']).revenue     # SeriesGroupBy  -> Series分组对象"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1a432246e929f17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3. 场景3: 如何获取某个分组的数据. \n",
    "df.groupby(['city', 'channel']).get_group(('北京', '线下'))     # 1个分组的信息\n",
    "df.groupby(['city', 'channel']).get_group(('上海', '线上'))     # 另1个分组的信息"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "880885e411f09ac9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 4. 场景4: 分组 + 聚合(聚合字段只有1个)\n",
    "# 需求: 根据 城市 和 销售渠道分组, 计算: 销售金额.\n",
    "# 写法1: 通用版(掌握)\n",
    "df.groupby(['city', 'channel']).agg({'revenue':'sum'})      # 返回DataFrame对象\n",
    "\n",
    "# 写法2: 变形版(了解)\n",
    "df.groupby(['city', 'channel']).revenue.sum()               # 返回Series对象\n",
    "df.groupby(['city', 'channel'])['revenue'].sum()            # 返回Series对象\n",
    "df.groupby(['city', 'channel'])[['revenue']].sum()          # 返回DataFrame对象"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1d5c5e022cfd2ac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5. 场景5: 分组 + 聚合(聚合字段有2个, 聚合操作相同)\n",
    "# 需求: 根据 城市 和 销售渠道分组, 计算: 销售金额, 订单数量 总和.\n",
    "# 写法1: 通用版(掌握)\n",
    "df.groupby(['city', 'channel']).agg({'revenue':'sum', 'order':'sum'})\n",
    "\n",
    "# 写法2: 变形版(了解)\n",
    "df.groupby(['city', 'channel'])[['revenue', 'order']].sum()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c81558fe8b765c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 6. 场景6: 分组 + 聚合(聚合字段有2个, 聚合操作不同)\n",
    "# 需求: 根据 城市 和 销售渠道分组, 分别计算: 销售金额的平均值, 成本的总和.\n",
    "df.groupby(['city', 'channel']).agg({\n",
    "    'revenue': 'mean',\n",
    "    'unit_cost': 'sum'\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "562d589a68444116"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 分组过滤"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "784ce23f557236af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 需求: 按照城市分组, 查询每组销售金额平均值 大于200的全部数据.    即: 算出每组的销售金额, 找到金额大于200的组, 然后显示这些组所有的信息.\n",
    "\n",
    "# 1.根据城市分组, 计算每个城市的 销售金额的 平均值\n",
    "df.groupby('city').revenue.mean()       \n",
    "\n",
    "# 2. 根据城市分组, 查看上海分组的数据.\n",
    "df.groupby('city').get_group('上海')\n",
    "\n",
    "# 3. 完成需求.\n",
    "df.groupby('city').filter(lambda x: x.revenue.mean() > 200)\n",
    "df.groupby('city').revenue.filter(lambda x: x.mean() > 200)\n",
    "\n",
    "# 4. 上边的代码等价于 找到  city值为 北京, 南京的数据. \n",
    "df.query('city in [\"北京\", \"南京\"]')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c478b66854ebcde"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. 交叉表(了解) 和 透视表(掌握)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3183015c18ddb195"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. 交叉表演示: \n",
    "# 创建一个示例数据集\n",
    "data = {\n",
    "    '性别': ['男', '女', '男', '女', '男', '女', '女', '男'],\n",
    "    '购买': ['是', '否', '是', '是', '否', '否', '是', '否']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 创建交叉表\n",
    "crosstab = pd.crosstab(df['性别'], df['购买'])\n",
    "print(crosstab)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7d29df60bcc8cbc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2. 用透视表完成上述的需求.\n",
    "data = {\n",
    "    '性别': ['男', '女', '男', '女', '男', '女'],\n",
    "    '购买': ['是', '否', '是', '是', '否', '否'],\n",
    "    '金额': [100, 150, 200, 130, 160, 120]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.pivot_table(index='性别', columns='购买', values='金额' , aggfunc='mean')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af099f834ba4eae6"
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "data": {
      "text/plain": "channel         线上         线下\ncity                         \n上海       114438.09  275383.64\n北京             NaN  130458.62\n南京             NaN  123150.93\n广州       200893.30  117231.19\n成都             NaN  208189.86\n杭州             NaN  589518.49\n武汉       281420.73  308357.05\n深圳             NaN  733123.68\n西安        30088.01  180686.61\n重庆        26330.35  237162.30",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>channel</th>\n      <th>线上</th>\n      <th>线下</th>\n    </tr>\n    <tr>\n      <th>city</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>上海</th>\n      <td>114438.09</td>\n      <td>275383.64</td>\n    </tr>\n    <tr>\n      <th>北京</th>\n      <td>NaN</td>\n      <td>130458.62</td>\n    </tr>\n    <tr>\n      <th>南京</th>\n      <td>NaN</td>\n      <td>123150.93</td>\n    </tr>\n    <tr>\n      <th>广州</th>\n      <td>200893.30</td>\n      <td>117231.19</td>\n    </tr>\n    <tr>\n      <th>成都</th>\n      <td>NaN</td>\n      <td>208189.86</td>\n    </tr>\n    <tr>\n      <th>杭州</th>\n      <td>NaN</td>\n      <td>589518.49</td>\n    </tr>\n    <tr>\n      <th>武汉</th>\n      <td>281420.73</td>\n      <td>308357.05</td>\n    </tr>\n    <tr>\n      <th>深圳</th>\n      <td>NaN</td>\n      <td>733123.68</td>\n    </tr>\n    <tr>\n      <th>西安</th>\n      <td>30088.01</td>\n      <td>180686.61</td>\n    </tr>\n    <tr>\n      <th>重庆</th>\n      <td>26330.35</td>\n      <td>237162.30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 透视表案例: 优衣库数据集.\n",
    "# 3.1 读取数据\n",
    "df = pd.read_csv('./data/uniqlo.csv')\n",
    "df\n",
    "\n",
    "# 3.2 需求: 根据城市, 销售渠道分组, 计算 销售金额 总和.\n",
    "# 写法1: groupby() 分组 聚合 \n",
    "df.groupby(['city', 'channel']).agg({'revenue': 'sum'})\n",
    "# df.groupby(['city', 'channel'], as_index=False).agg({'revenue': 'sum'})     # as_index=False 不把分组字段当做行索引, 而是当做列.\n",
    "\n",
    "# 写法2: pivot_table() 透视表, 作用: 统计分组数据, 简化 分组聚合写法, 指定某一列对另一列的关系\n",
    "# 参1: 指定分组字段, 参2: 指定分组字段, 参3: 指定聚合字段, 参4: 指定聚合函数\n",
    "df.pivot_table(index='city', columns='channel', values='revenue', aggfunc='sum')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-31T10:24:36.414898900Z",
     "start_time": "2025-03-31T10:24:36.364555Z"
    }
   },
   "id": "b25031b9daf6d128"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e7289142571608a4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
