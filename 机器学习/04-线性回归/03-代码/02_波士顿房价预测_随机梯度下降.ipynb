{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0a01056-1b44-4e7d-9d6f-a5f4fcc8f450",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "案例:\n",
    "    演示 随机梯度下降法 线性回归对象 完成 波士顿房价预测案例.\n",
    "\n",
    "回顾:\n",
    "    线性回归算法 属于 有监督学习之  有特征, 有标签, 且标签是连续的.\n",
    "    线性回归分类:\n",
    "        一元线性回归: 1个特征列, 1个标签列.\n",
    "        多元线性回归: 多个特征列, 1个标签列.\n",
    "    线性回归大白话解释:\n",
    "       它是用线性公式来描述 特征 和 标签之间关系的, 方便做预测, 公式如下:\n",
    "       一元线性回归: y = w * x + b\n",
    "       多元线性回归: y = w1 * x1 + w2 * x2 + w3 * x3 + ... + wn * xn + b = w的转置 * x + b\n",
    "    如何衡量线性回归模型的好坏?\n",
    "        思路:\n",
    "            预测值和真实值之间的误差, 误差越小, 模型越好 => 损失函数\n",
    "        具体的方案:\n",
    "            1. 最小二乘.        每个(样本)误差平方和\n",
    "            2. 均方误差(MSE)    每个(样本)误差平方和 / 样本总数\n",
    "            3. 均方根误差(RMSE)  每个(样本)误差平方和 / 样本总数 的 平方根\n",
    "            4. 平均绝对误差(MAE) 每个(样本)误差绝对值和 / 样本总数\n",
    "    如何让损失函数最小?\n",
    "        思路1: 梯度下降法.     =>   全梯度下降(Full Gradient Descent, FGD), 随机梯度下降(SGD), 小批量梯度下降(推荐, Min-Batch), 随机平均梯度下降(SAG)\n",
    "        思路2: 正规方程法.\n",
    "\n",
    "    机器学习开发流程:\n",
    "        1. 加载数据.\n",
    "        2. 数据的预处理.\n",
    "        3. 特征工程(特征提取, 特征预处理...)\n",
    "        4. 模型训练.\n",
    "        5. 模型预测.\n",
    "        6. 模型评估\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0535999c-a5d6-403f-bf68-5afc7b141abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导包\n",
    "from sklearn.preprocessing import StandardScaler        # 特征处理\n",
    "from sklearn.model_selection import train_test_split    # 数据集划分\n",
    "from sklearn.linear_model import LinearRegression       # 正规方程的回归模型\n",
    "from sklearn.linear_model import SGDRegressor           # 梯度下降的回归模型\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, mean_absolute_error  # 均方误差评估, RMSE, MAE\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b854b30-8c93-48cb-9bbd-44cdf1b35bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 加载 波士顿房价数据.\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])  # hstack()函数作用: 水平拼接数组\n",
    "target = raw_df.values[1::2, 2]\n",
    "# print(f'特征: {data.shape}')      # (506, 13)\n",
    "# print(f'标签: {target.shape}')    # (506,)\n",
    "#\n",
    "# print(f'特征数据: {data[:5]}')\n",
    "# print(f'标签数据: {target[:5]}')\n",
    "\n",
    "# 2. 数据的预处理.  按照8:2 切分 训练集和测试集.\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=23)\n",
    "\n",
    "# 3. 特征工程(特征提取, 特征预处理...)\n",
    "# 3.1 创建 标准化对象.\n",
    "transfer = StandardScaler()\n",
    "# 3.2 对训练集和测试集进行标准化处理.\n",
    "x_train = transfer.fit_transform(x_train)\n",
    "x_test = transfer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c30a5cc-8f14-46dd-aa69-089073075f84",
   "metadata": {},
   "source": [
    "# 4. 模型训练."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85b842d8-ea70-4ba3-b37d-d0228bbd6df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "权重: [-0.35476412  1.05985222  0.23696638  0.83646163 -2.06670058  2.84275975\n",
      "  0.28744075 -3.31442585  2.65346763 -1.06413268 -1.74009159  1.06456605\n",
      " -4.1023618 ]\n",
      "偏置: [22.95087426]\n"
     ]
    }
   ],
   "source": [
    "# estimator = LinearRegression(fit_intercept=True)    # 正规方程法 线性回归对象.\n",
    "\n",
    "# 4.1 创建 梯度下降 线性回归 模型对象.\n",
    "# 参1: fit_intercept: 是否计算截距.\n",
    "# 参2: learning_rate: 学习率模式 -> 常量, 即: 不会发生改变.\n",
    "# 参3: eta0: 学习率.\n",
    "estimator = SGDRegressor(fit_intercept=True, learning_rate='constant', eta0=0.01)\n",
    "\n",
    "# 4.2 模型训练.\n",
    "estimator.fit(x_train, y_train)\n",
    "# 4.3 打印 权重 和 偏置.\n",
    "print(f'权重: {estimator.coef_}')\n",
    "print(f'偏置: {estimator.intercept_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c650073-eeef-42d0-a086-68effb7dfd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 模型预测.\n",
    "y_pre = estimator.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d5929a1-a818-4b77-a6f5-2fa669820db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "均方误差: 26.49109146157858\n",
      "均方根误差: 5.146949724018934\n",
      "平均绝对误差: 3.9984888175046516\n"
     ]
    }
   ],
   "source": [
    "# 6. 模型评估\n",
    "# MSE: 均方误差, 每个误差的平方和 / 样本总数\n",
    "print(f'均方误差: {mean_squared_error(y_test, y_pre)}')          # 参1: 测试集的真实标签, 参2: 测试集的预测标签\n",
    "\n",
    "# RMSE: 均方根误差, 均方误差的平方根\n",
    "print(f'均方根误差: {root_mean_squared_error(y_test, y_pre)}')   # 参1: 测试集的真实标签, 参2: 测试集的预测标签\n",
    "\n",
    "# MAE: 平均绝对误差, 每个误差绝对值和 / 样本总数\n",
    "print(f'平均绝对误差: {mean_absolute_error(y_test, y_pre)}')     # 参1: 测试集的真实标签, 参2: 测试集的预测标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaa9143-b36e-468c-b4ad-8c089edfacc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
