{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce05a7db-7db2-443b-8552-ea42b62fee59",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "线性回归介绍(Linear Regressor):\n",
    "    概述/目的:\n",
    "        用线性公式 来描述 多个自变量(特征)  和 1个因变量(标签)之间 关系的, 对其关系进行建模, 基于特征 预测 标签.\n",
    "        线性回归属于: 有监督学习, 即: 有特征, 有标签, 且标签是连续的.\n",
    "    分类:\n",
    "        一元线性回归:  1个特征列 + 1个标签列\n",
    "        多元线性回归:  多个特征列 + 1个标签列\n",
    "    公式:\n",
    "        一元线性回归:\n",
    "            y = kx + b => wx + b\n",
    "                k: 数学中叫斜率, 在机器学习中Weight(权重), 简称: w\n",
    "                b: 数学中叫截距, 在机器学习中Bias(偏置), 简称: b\n",
    "        多元线性回归:\n",
    "            y = w1x1 + w2x2 + w3x3 + ... + wnxn + b\n",
    "              = w的转置 * x + b\n",
    "\n",
    "    误差 = 预测值 - 真实值\n",
    "    损失函数(Loss Function, 也叫成本函数, 代价函数, 目标函数, Cost Function):\n",
    "        用于描述 每个样本点 和 其预测值之间关系的, 让损失函数最小, 就是让 误差和小, 线性回归效率, 评估就越高.\n",
    "    问题: 如何让损失函数最小?\n",
    "    答案:\n",
    "        思路1: 正规方程法.\n",
    "        思路2: 梯度下降法.\n",
    "\n",
    "    损失函数分类:\n",
    "        最小二乘: 每个样本点误差的平方和\n",
    "        MSE(Mean Square Error, 均方误差): 每个样本点误差的平方和 / 样本个数\n",
    "        RMSE(Root Mean Square Error, 均方根误差): 均方误差 开平方根\n",
    "        MAE(Mean Absolute Error, 均绝对误差): 每个样本点误差的绝对值和 / 样本个数\n",
    "\n",
    "矩阵相关:\n",
    "    1范数 = 向量中各元素 绝对值 之和.\n",
    "    2范数 = 向量的模长, 即: 各个元素平方总和, 开平方根\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a83dd98-9711-459b-9290-f1814dc84e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导包\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8320d5-813a-4749-88ea-8d00cd783eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 准备数据.\n",
    "x_train = [[160], [166], [172], [174], [180]]       # 训练集的特征\n",
    "y_train = [56.3, 60.6, 65.1, 68.5, 75]              # 训练集的标签\n",
    "x_test = [[176]]                                    # 测试集的特征\n",
    "\n",
    "# 2. 数据的预处理, 这里不需要.\n",
    "# 3. 特征工程(特征提取, 特征预处理), 这里不需要."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a706cc2f-a3af-4928-a975-65687a216d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "权重: [0.92942177]\n",
      "偏置: -93.27346938775517\n"
     ]
    }
   ],
   "source": [
    "# 4. 模型训练\n",
    "# 4.1 创建模型对象.\n",
    "estimator = LinearRegression()\n",
    "# 4.2 具体的训练动作.\n",
    "estimator.fit(x_train, y_train)\n",
    "# 4.3 因为是线性回归模型, 我们可以查看下: 斜率(w, 权重), 截距(b, 偏置)\n",
    "print(f'权重: {estimator.coef_}')         # 0.92942177\n",
    "print(f'偏置: {estimator.intercept_}')    # -93.27346938775514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3899e92b-8f33-4c32-a723-eec2f4b90a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测值为: [70.3047619]\n"
     ]
    }
   ],
   "source": [
    "# 5. 模型预测.\n",
    "y_pre = estimator.predict(x_test)\n",
    "print(f'预测值为: {y_pre}')               # 70.3047619"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86daa6f1-972d-4721-a3db-d7ad79daf8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
